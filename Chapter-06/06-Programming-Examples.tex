\chapter{Programming Examples}

\TallC{This} chapter illustrates how we may apply the floating point extensions of FORTH, developed in preceding chapters, to some standard problems in numerical analysis.

\section{Infinite series}

Frequently we must evaluate a function defined by an infinite sum

\begin{align}
    f(x) = sum_{n=0}^{\infty}c_{n}x^{n}
\end{align}

where $x$ is a real number and $c_n$ is an infinite sequence of coefficients. The extensive mathematical theory\sepfootnote{06_01} of such functions tions can be summarized as follows: the series of terms only have meaning if -for fixed $x$- the sequence of partial sums

\begin{align}
    f_{N}(x) = sum_{n=0}^{N-1}c_{n}x^{x}
\end{align}

has a definite limit.

\subsection{Examples of Infinite series}
\TallC{Perhaps} the formal definitions will seem clearer after some concrete examples. We now examine some divergent an convergent series.

\subsubsection{Divergent examples}
What does it mean to say a series diverges? Consider the serices whose terms are all 1's (that is, $c_n = 1, x = 1$):

\begin{align}
    1 + 1 + 1 + 1 + ...
\end{align}

The partial sum $f_N$ is just $N$, and therefore increases without limit as more terms are added. The series \textit{diverges}.

A harder case is the series whose terms are alternately 1's and -1's:

\begin{align}
    1 - 1 + 1 - 1 + 1 - ...
\end{align}

Depending on how the terms are grouped together, the partial
sums can have any value. Certainly the partial sums do not settle
down to any definite value. The series \textit{diverges}.

Yet a third case is the harmonic series

\begin{align}
    f_{N} = 1 + \frac{1}{2} + \frac{1}{3} + \frac{1}{4} + ... + \frac{1}{N}
\end{align}

It can be shown that for large $N$, $f_{N}$ is approximately $log_{e}(N)$, so the harmonic series \textit{diverges}.

\subsubsection{A convergent example}
Are there ever mes of infinite series that \textit{do} mean something? Obviously, or there could hardly be a theory of them! An example\sepfootnote{06_02} is $c_{n}=1, x = \frac{1}{2}$. Here the partial sums

\begin{align}
f_{0} =& 1                               \\
f_{1} =& 1 + \frac{1}{2}                 \\
f_{2} =& 1 + \frac{1}{2} + \frac{1}{4}   \\
........&........                        \\
\lim_{N\to\infty} f_{N} \equiv \lim_{N\to\infty} \frac{1-(\frac{1}{2})^{N}}{1-\frac{1}{2}} = 2
\end{align}

\textit{do} have a definite limit, so the series converges.

\subsection{Numerical examples of convergent series}
\TallC{How} do we tell whether a series has converged? As a practice matter, we keep adding terms to the partial sum until it no longer changes, within the desired precision. Sometimes this can involve a great many terms, even when the series converges. There exists an extensive mathematical literature on testing for the convergence of an infinite series. Mathematicians have also developed many tricks for accelerating the convergence of slow converging series\sepfootnote{06_03}. Consulting the literature in difficult cases I strongly recommended - it can save time galore!

As an heuristic exercise, let us write some simple programs to evaluate partial sums and see how convergence works.

first we sum the terms $2^{-n}$ from Eq. 6. The flow diagram is shown in Fig. \ref{fig:06_01} below.

%\tikzstyle{line} = [draw, -latex']
\tikzset{%
  do path picture/.style={%
    path picture={%
      \pgfpointdiff{\pgfpointanchor{path picture bounding box}{south west}}%
        {\pgfpointanchor{path picture bounding box}{north east}}%
      \pgfgetlastxy\x\y%
      \tikzset{x=\x/2,y=\y/2}%
      #1
    }
  },
  cross/.style={do path picture={    
    \draw [draw, -latex', cap=round] (-1,-1) -- (1,1) (-1,1) -- (1,-1);
  }},
  dot/.style={do path picture={    
    \draw [fill]  circle [radius=1]; 
  }}
}
\begin{figure}
% Fig. 6-1 
    \begin{tikzpicture}[minimum size=0.75cm]
        \draw (8,0.5) -- (-4, 0.5) -| (-4,-10) |- (8,-10);
        \node (start) {};
        \node [circle, draw, cross, below=0.5cm of start] (cross) {};
        \node [right=of cross, xshift=-0.5cm] (cyc) {BEGIN} ;
        \node [above =1.0cm of cyc.west,anchor=west] {SET UP: \space N=0 \space SUM=1};
        \node [below=1.5cm of cyc.west, anchor=west, align=left, text width=6cm, xshift=-0.5cm] {?CONTINUE ( 10 or more terms? )\\WHILE} ;
        \node [below= of cross] (cond) {};
        \node [circle, draw, cross, below= of cond] (cross2) {};
        \node [circle, draw, dot, below=1.6cm of cross2] (dot1)  {};
        \node [circle, draw, dot, below= of dot1] (dot2)  {};
        \node [left=of cond] (NO) {};
        \node [draw, fill, opacity=0.2, below= of NO, text width=1.2cm]  (ext) {};
        \draw [->] (start) -- (cross);
        \draw [->] (cross) -- (cond.mid);
        \draw [->] (cond.mid) -- (cross2);
        \draw [->] (cross2) -- (dot1);
        \draw [->] (dot1) -- (dot2);
        \draw [->] (cond.mid) -- (NO.mid);
        \draw [->] (NO.mid) -- (ext);
        \node [right=of dot1, align=left, xshift=-0.5cm] {LOOP} ;
        \node [right=of dot2, align=left, xshift=-0.5cm] {REPEAT} ;

        \node [right= of cross2, align=left, xshift=-0.5cm] (lp0) {10 \space 0 \space DO} ;
        \node [below=.5cm of lp0.mid,anchor=west, align=left, xshift=-0.3cm] (lp1) {$2^{-n-1}=2^{-n}/2$} ;
        \node [below=.5cm of lp1.west,anchor=west, align=left] (lp2) {SUM = SUM + $2^{-n-1}$} ;
        \node [below=.5cm of lp2.west,anchor=west, align=left] (lp3) {n = n + 1} ;
        \node [left=.1cm of cond.south, align=left] (TYES) {YES} ;
        \node [left=.1cm of NO.south, align=left] (TNO) {NO} ;
        \node [below=-0.1cm of ext.south, align=left] (TEXIT) {Exit} ;
    \end{tikzpicture}
    \caption{\textit{Computing 2 the hard way}}
    \label{fig:06_01}
\end{figure}

The corresponding program is

\begin{lstlisting}
    15 #PLACES !            \ set F. to 15 digits
    : NEXT.TERM
        ( n -- n+1 :: sum 2^-n -- sum'2^-n-1 )
        F2/ FUNDER F+ FSWAP 1+ ;
    : SET.UP FINIT F=1 F=1 0 ;
    : EXHIBIT CR DUP ." n = " .
        2 SPACES
        FOVER ." sum = " F. ;
    : ?CONTINUE  CR ." Another 10 terms?" ?YN ;
    \ ?YN expects a "y" or "n" from the keyboard and
    \ leaves -1 ( "true" ) if "y" is pressed, 0 if "n"
    : SUM SETUP
        BEGIN EXHIBIT ?CONTINUE
        WHILE 10 0 DO NEXT.TERM LOOP
        REPEAT ;
\end{lstlisting}

This is what a run looks like:

\begin{lstlisting}
FLOAD TEST.SUM Loading TEST.SUM ok
SUM
n = 0  sum = 1.00000000000000
Another 10 terms? Y
n = 10 sum = 1.919902343750000
Another 10 terms? Y
n = 20 sum = 1.99999904632568
Another 10 terms? Y
n = 30 sum = 1.99999999906867
Another 10 terms? Y
n = 40 sum = 1.99999999999909
Another 10 terms? N ok
\end{lstlisting}

The partial sums converge rapidly to 2 (which, as we saw in Ch. 1.1.2 above, is the exact sum).

For a second example, let us sum a standard infinite series representation for $\pi/4$: We note that the function $\tan^{-1}(x)$(that is, arctan(x) ) has the infinite series representation\sepfootnote{06_04}

\begin{align}
    \tan^{-1}(x) = x - \frac{x^{3}}{3} + \frac{x^{5}}{5} - \frac{x^{7}}{7} ...
\end{align}

Since a 45$^{\circ}$ right triangle has equal height and base, the tangent of 45$^{\circ}$ is 1 (side opposite over side adjacent). That is\sepfootnote{06_05},
\begin{align}
    \frac{\pi}{4} \equiv \tan^{-1}(1) = 1 - \frac{1}{3} + \frac{1}{5} - \frac{1}{7} + \frac{1}{9}...
\end{align}

Actually the series Eq. 8 is slowly converging and therefore a poor way to compute $\pi$\sepfootnote{06_06}. But anyway, let us proceed. The flow diagram is now that of Fig. \ref{fig:06_02} below.

% Fig. 6-2 
\begin{figure}
    \begin{tikzpicture}[minimum size=0.5cm]
        \draw (-2, 0.5) rectangle (10,-7);
        \node (start) {};
        \node [circle, draw, cross, below=0.5cm of start] (cross) {};
        \node [below=0.5cm of cross] (cond) {};
        \node [circle, draw, dot, below right= 4.5cm and 2cm of cross] (dot1)  {};
        \node [left=of cond] (NO) {};
        \node [draw, fill, opacity=0.2, below= 1.5cm of NO, text width=1.2cm,xshift=.8cm]  (ext) {};
        \draw [->] (start.mid) -- (cross);
        \draw [->] (cross) -- (cond.mid) -- ++(-.75, -0.75) -- (ext);
        \draw [->] (cond.mid) -| (dot1);
        \node [right=of dot1, align=left, xshift=-0.8cm, yshift=0.25cm] {REPEAT} ;

        \node [below=-0.1cm of ext.south, align=left] (TEXIT) {Exit} ;
        \node [right=of cross, xshift= 1.5cm] (cyc) {BEGIN} ;
        \node [above =1.0cm of cyc.west,anchor=west] {SETUP: flag=1 n=1 sum=0 ( -\phantom{}- 1 n ::-\phantom{}-0)};
        \node [below=1.3cm of cyc.west, anchor=west, align=left, text width=6.5cm, xshift= 0.5cm] (blob) {
            EXHIBIT \hspace{0.6cm} \textbackslash \space display n, sum \\
            ?CONTINUE  \space \space \space WHILE \\
                \leavevmode    \\
            DUP S-\textgreater F  \space 1/F  \space   ( -\phantom{}- fn :: -\phantom{}- sum 1/n ) \\
            SWAP FDUP FSIGN \textbackslash \space transfer sign\\
        };
        \node [below=1.7cm of blob.west, anchor=west, align=left, text width=7cm, xshift= -0.2cm] {
            F+  
            \hspace{3.2cm}
            \textbackslash  \space sum = sum +\\ 
            term\\
            NEGATE  \hspace{2.0cm}  \textbackslash  \space flip sign of f
        };
    \end{tikzpicture}
    \caption{\textit{Computing $\pi/4$ by the infinite series for $\tan^{-1}(1)$}}
    \label{fig:06_02}
\end{figure}


The corresponding program is
\begin{lstlisting}
    15 #PIACES ! \ set F. to 15 digits
    : NEXT.TERM ( f 2n+1 -- f1 2n+3 :: sum -- sum1 )
        DUP S->F 1/F SWAP DUP FSIGN F+
        NEGATE SWAP 2+ ;
    : SETUP FINIT F=0 1 1 ;
    : EXHIBIT CR DUP
        ." n = " . Z SPACES
        FDUP F2* F2* ." 4*sum = " F. ;
    : ?CONTINUE ." Another term?' ?YN ;

    : PI/4 SET.UP
        BEGIN EXHIBIT
        ?CONTINUE
        WHILE NEXT.TERM REPEAT ;
\end{lstlisting}

Now we run the program\sepfootnote{06_07}:

\begin{lstlisting}
FLOAD PIBY4 Loading PIBY4 ok
PI/4

n = 1  4*num = Another term? Y
n = 3  4*num = Another term? Y
n = 5  4*num = Another term? Y
n = 7  4*num = Another term? Y
n = 9  4*num = Another term? Y
n = 11 4*num = Another term? Y
n = 13 4*num = Another term? Y
n = 15 4*num = Another term? Y
n = 17 4*num = Another term? Y
n = 19 4*num = Another term? Y
n = 21 4*num = Another term? Y
n = 23 4*num = Another term? Y

n = 25 4*num = Another term? Y
n = 27 4*num = Another term? Y
n = 29 4*num = Another term? Y
n = 31 4*num = Another term? Y
n = 33 4*num = Another term? Y
n = 35 4*num = Another term? Y
n = 37 4*num = Another term? Y
n = 39 4*num = Another term? Y
n = 41 4*num = Another term? Y
n = 43 4*num = Another term? Y
n = 45 4*num = Another term? Y
n = 47 4*num = Another term? Y
\end{lstlisting}

The first thing we notice is that the numbers seem to be converging to \textit{something}; however, unlike the previous series, the differences between successive partial sums are fairly large.

An infinite series of terms that alternate in sign and decrease in magnitude is guaranteed to converge\sepfootnote{06_08}. The error (that is, the difference between a partial sum and the limit) is of the order of the first neglected term and has the same sign. We see that for this case, the error in computing $\pi$ is of order $2/n$, where $n$ is the number of terms in the sum. To get $\pi$ to 3 significant figures, therefore, we need about 1000 terms! This is why the series representation for $4\tan{1}^{-1}$ is not a very good way to calculate $\pi$ A better way uses \eg,

\begin{align*}
    \pi = 16\tan^{-1}\left ( \frac{1}{5}\right ) - 4\tan^{-1}\left(\frac{1}{239}\right) ,
\end{align*}

, which converges much faster\sepfootnote{06_09}.

\subsubsection{The infinite sum program}
Evaluating a function from its infinite series representation Eq. 1 provides an illustration both of indefinite loops and of tests of floating point numbers. We anticipate a program structure something like this:

\begin{lstlisting}
    BEGIN
      Calculate next term
      Not converged?
    WHILE
      Update:
        Add next term to sum
        increment n
    REPEAT
\end{lstlisting}

To actually write the program, we begin at the end, by specifying how we want to invoke the function.

Functions in the standard FORTH library (Ch. 3.3) typically expect a single real number on the fstack replacing it with the function: $x \rightarrow f(x)$. Since the sum is infinite, we supply the coeifcients $c_n$ as a function of $n$ rather than as an array. For any given $c_n=f(n)$, it is easy enough to write a FORTH word that evaluates it and leaves the result on the appropriate stack (87stack, fstack, ifstack). For example, to evaluate the exponential \textit{via} the power series

\begin{align}
e^x = 1 + \frac{x^1}{1!} + \frac{x^2}{2!} + \frac{x^3}{3!} + ...
\end{align}

we would define the word NEXT.TERM as

\begin{lstlisting}
    : NEXT.TERM ( 87: term x n -- term*x/[n+1] x n+1 )
        F=1 F+ \n-> n+1
        FROT FOVER F/ ( 87: -- x n+1 term/[n+1])
        FROT FUNDER F* F-ROT ;
\end{lstlisting}

\subsubsection{Function calls In FORTRAN}
However, FORTRAN (as well as languages that emulate it) achieves readability by passing arguments to functions in a list. In fact, function names can also be passed in the argument list. Thus, \eg, a general FORTRAN program to evaluate a function by summing an infinite series could be written

\begin{lstlisting}
    REAL FUNCTION XINFSUM(X. E. C)
C
C   EVALUATE INFINITE POWER SERIES
C
    EXIERNAL C
    REAL X, E, C
    SUM  = 0
    TERM = 1
    N = 1
1   SUM  = SUM + TERM
    TERM = TERM*X*C(N)
    N = N + 1
    IF (TERM .LE. E) RETURN
    GOTO 1
    END
\end{align}

where the program to evaluate the exponential would be

\begin{lstlisting}
    REAL FUNCTION EXP(x)
    EXTERNAL XINFSUM, COEFEXP
    REAL C0, XINFSUM
    COMMON /C8LK/C0
    C0 = 1
    EXP = XINFSUM(X, 1.E-7, C0EFEXP)
    RETURN
    END
\end{lstlisting}

given the coefficient function

\begin{lstlisting}
REAL FUNCTION OOEFEXP(N)
COMMON /C8LK/C0
C0 = C0/N
COEFEXP = C0
RETURN
END
\end{lstlisting}

\subsubsection{A function protocol for FORTH}

We would like to extend to FORTH FORTRAN’s ability to write a generic series summation function, passing the variable and the name of the coefficient function as arguments. In other words, we now face the task of devising the function protocol we plan to use throughout the rest of the book and in our future programming - a heavy responsibility since we do not know what form these future programs will take. \textbf{For once we must engage in top-dawn programming!}

We want our protocol to have several features:
\begin{itemize}
    \item It must be \textbf{telegraphic}, \ie it must immediately suggest what it is doing - a matter of choosing good names.
    \item It must be simple to implement and easy to remember - the advantages of using it must not be outweighed by complexity.
    \item It must be fast - a major drawback to FORTRAN's way of doing things is the overhead in function calls.
    \item It must be portable -- it cannot depend on specific details of the FORTH implementation or the machine 1t 1s running on.
\end{itemize}

It is simpler to thread this particular maze in reverse: begin with where we want to end up, and determine what steps got us there. We suppose we have defined a generic power series summation function, using the ifstack defined in Ch. 5.2.5:
\begin{lstlisting}
    : SUMPOWERS         ( 87: err -- :: x -- sum )
    E G!                \ store error
    FS>F DUP F>FS       \ get type of x
        DUP G=1         \ x**0
        G=0 0 DUP       ( -- n=0 :: -- x 1 0 )
    adr.c EXECUTE G+    ( -- 0   :: -- x 1 c[0] )
BEGIN 1+ --n::~-xx“n-13um)
    FS>F GOVER G*
        ( -- n 87: -- sum :: -- x x**n)
    DUP adr.c EXECUTE
        ( -- n :: -- x x**n )
    3 GPICK G* F>FS
        ( -- n :: -- x x**n term sum )
    ENUF? NOT WHILE
        G+
    REPEAT G+ CLEANUP ;
\end{lstlisting}

The words E, ENUF? and CLEANUP have straightforward definitions with obvious meanings; adr.c has not been defined because we have yet to figure out what it will do.

Manifestly, edr.c must place the execution address ("code-field address" -- cfa) on the stack for EXECUTE to find. There are several ways to accomplish this. Clearly, we want to keep the variable that holds the cfa local, so it will not get confused with another function's cfa. While it is straightforward to define a variable and then make it headerless --hence local-- (via BEHEAD", e.g.) we would prefer to avoid defining a variable at all. Here is a perfect opportunity to use the return stack (rstack).

We imagine that SUM.POWERS expects the cfa of the function $c_n$ on the stack. Then the first thing SUM.POWERS must do is stash the cfa somewhere convenient but local. One such place is the stack itself. Even easier, since SUM.POWERS does not use the rstack explicitly (e.g. in a DO ... LOOP), is to let the first step in SUM.POWERS be >R. Then the code for adr.c would be merely R@. The final word, after invoking CLEAN.UP (that drops unwanted items from the various stacks), then must be RDROP (for systems without it, : RDROP R> DROP ; ).

The revised version of SUM.POWERS is then
\begin{lstlisting}
: SUM.POWERS    ( adr.c -- 87: err -- :: x -- sum )
    > R             \ adr.c -> rstack
    E G!            \ store error
    FS>F  DUP F>FS  \ get x's type
          DUP G=1   \ x**0
    G=0 0 DUP       ( -- n=0 :: -- x 1 0 )
    R@ EXECUTE G+   ( -- 0   :: -- x 1 c[0] )
    BEGIN 1+        ( -- n   :: -- x x**n-1 sum )
        FS>F GOVER G*  ( -- n 87: -- sum :: -- x x**r )
        DUP R@ EXECUTE ( -- n:: -- x x**n c[n] )
        3 GPICK G* F>FS( -- n:: -- x x**n term sum )
        GOVER
    ENUF? NOT   WHILE G+ REPEAT
    G+ CLEAN.UP RDROP ;
\end{lstlisting}

The full program to evaluate the exponential by summing power series would then have the form shown below:

\ evaluate exponential by summing series
REAL*4 SCALAR E
: ENUF? (::term--) (--F)
    GABS FS>F EG@ F> ;
: CLEAN.UP ( n-- ::x x**n sum -- sum )
    DROP FS >F
    GDROP GDROP F>FS ;
\ definition of SUM.POWERS from above
BEHEAD" E CLEAN.UP \ hide these def'ns
REAL*8 SCALAR c F=1 c G!
: COEEEXP (n--) (:: -- c[n] )
    DUP 1 < =
    IF F=1 c G! F=1 DROP
    ELSE c G@ S->F
        F* FDUP c G! 1/F

    THEN REAL*4 F>FS ;
BEHEAD' c \ hide this variahie
: USE( [COMPILE] ' CFA LITERAL ;
    IMMEDIATE
\ this means "use address of"
\ --crucial def'n of function lexicon
:E**X (::x--e**x) %1.E-8
            \ error on 87stack
    USE( COEFF.EXP
            \ adr.c on stack
    SUMPOWERS ;

\section{Transcendental equations}

\TallC{A transcendental} equation has the form

f(x) = 0,

where f(x) is a transcendental function rather than, say, a polynomial or ratio of polynomials\sepfootnote{06_10} (\textbf{rational} function).

There are several standard methods for finding a (or possibly, the) value of x that satisfies this equation, i.e. a root of Eq. 10 (which might have many or no roots). To guarantee that we find a root we must know an interval of the x-axis that it certainly will be found in. Two methods that can be applied under these circumstances are binomial search and regula falsi.

\subsection{Binary search}

Let us look first at binomial search, since its algorithm is euy to understand. We know some interval, $x_L \leq x \leq x_r$, contains a root because $f(x)$ changes sign when x goes from $x_L \rightarrow x_R$. In pseudocode (and FORTH flow chart) the binomial search algorithm is shown in Fig. 6-3 on page 128.

The method begins with upper and lower bounds on x that capture the root. Next we look at $f(x_AV)$ halfway between $x_L$ and $x_R$. If $f=f(x_AV)$ has the same sign as $f_L = f(x_L)$, the new left end of the interval becomes $x_AV$. If the signs are opposite, $x_AV$ becomes the new right end of the interval. The algorithm is done when left and right ends agree within some predetermined accuracy.

Binary search has the following virtues: the time it takes to achieve a given accuraqr is predictable, and it is guaranteed to find a captured root. Creating a FORTH program from the pseudocode skeleton of Fig. \ref{fig:06_03} is left as an exercise.
%  Fig. 6-3 
\begin{figure}
    \begin{tikzpicture}[minimum size=0.5cm]
        \draw (-2.8, 0.15) rectangle (9,-8.8);
        \node (start) {};
        \node [circle, draw, cross, below= of start] (cross) {};
        \node [below=0.8 of cross] (cond) {};
        \node [below=1.6cm of cond] (cond2) {};
        \node [draw, below right=0.2cm of cond2, text width=1.5cm, align=center] (NO) {NO\\$x_R=x$\\$f_R=f$};
        \node [draw, below left=0.2cm of cond2, text width=1.5cm, align=center] (YES) {YES\\$x_L=x$\\$f_L=f$};
        \node [circle, draw, dot, below=2.8cm  of cond2] (dot1)  {};
        \node [draw, fill, opacity=0.2, below left= of cond, text width=0.6cm, minimum height= 0.25cm, xshift=-0.4cm]  (ext) {};
        \draw [->] (start.mid) -- (cross);
        \draw [->] (cross) -- (cond.mid);
        \draw [->] (cond.mid) -| (ext);
        \draw [->] (cond.mid) -| (cond2.mid);
        \draw [->] (cond2.mid) -| (YES);
        \draw [->] (cond.mid) -| (cond2.mid);
        \draw [->] (cond2.mid) -| (NO);
        \draw [->] (YES.south) -- ++(0,-0.5cm);
        \draw [->] (YES.south) |- ++(0,-0.5cm) -| (dot1);
        \draw [->] (NO.south) -- ++(0,-0.5cm);
        \draw [->] (NO.south)  |- ++(0,-0.5cm) -| (dot1);
        \node [below=-0.1cm of ext.south, align=left] (TEXIT) {Exit} ;
        \node [right=of cross, xshift= 1.5cm] (cyc) {BEGIN} ;
        \node [above =1.0cm of cyc.west,anchor=west, align=left, text width=6.5cm] {
            INITIALIZE\\
            $\mathrm{f_L=f(x_L) \quad f_R=f(x_R)}$};
        \node [below=0.5 of cyc.west, anchor=west, align=left, xshift= 0.5cm] (body) {$\mathrm{\left | x_L - x_R \right |} > error?$ };
        \node [below= of cyc.west, anchor=west, align=left] (while) {WHILE};
        \node [below= of while.west, anchor=west, align=left] (eq3) {$x=\frac{1}{2}\left (x_L + x_R \right )\,,\;f=f(x)$};
        \node [below= of eq3.west, anchor=west, align=left] (eq3) {sign(f) = sign(fL)?};
        \node [below=0.8cm of eq3.west, anchor=west, align=left, xshift= -0.2cm] (eq4) { IF   \hspace{1.2cm} $\mathrm{x_L=x \quad f_L=f}$};
        \node [below=0.8cm of eq4.west, anchor=west, align=left] (eq5) { ELSE \hspace{0.6cm} $\mathrm{x_R=x \quad f_R=f}$};
        \node [below=0.8cm of eq5.west, anchor=west, align=left] (eq6) { THEN };
        \node [below=1.3cm of eq6.west, anchor=west, align=left] (eq7) { REPEAT };
    \end{tikzpicture}
    \caption{\textit{Binary search algorithm for roots of f(x)}}
    \label{fig:06_03}
\end{figure}




\subsection{Regula falsi}

\TallC{Now we} look at \textit{regula falsi}, Latin for "rule of false approach" Here the basic premise is:

\begin{itemize}
    \item Assume the root lies in the interval (x1, x3, and plot a straight line between the points $(x_L, f_L)$ and $(x_R, f_R)$.

    \item This line must intersect the x-axis somewhere in the interval, and we take that point, call It $x’$, as our next guess.

    \item If $x’$ is to the left of the root, adjust the interval accordingly, an the same if $x’$ is to the right of the root.
\end{itemize}

As Fig. \ref{fig:06_04} on page \pageref{fig:06_04} shows, the straight line is supposed
approximate the curve f(x). The new guess may be much closer to the root than is the midpoint of the interval (which was the next guess in binomial search).

%  Fig. 6-4 
\begin{figure}
    \center
    \begin{tikzpicture}
        \draw (-3.4, -1.8) rectangle (7.2,6.5);
        \coordinate (O) at (0,0);
        \draw (-3,0) -- (6,0);
        \draw (0,-1.3) -- (0,6.2);
        \foreach \x in {-2.4,-0.4,0.6,1.6,2.6,3.6,4.6,5.6}
            \draw (\x cm,2pt) -- (\x cm,-0pt) node[anchor=north] {$\x$};
        \foreach \x in {-1.9,...,5.1}
            \draw (\x cm,1pt) -- (\x cm,-0pt);
        \foreach \y in {-1.25,-0.5,0.75,1.75,2.75,3.75,4.75,5.75}
            \draw (2pt,\y cm) -- (0pt,\y cm);
        \foreach \y in {-1.25,0.75,2.75,4.75}
            \node[anchor=east] at (0pt,\y cm) {$\y$};

        \draw (2.2,0) -- ++(0,0.5);
        \node  at (2.1,0.75) {"binary" next};

        %\path[name path=x] (0.3,0.5) -- (6.7,4.7);
        %\path[name path=y] plot[smooth] coordinates {(-0.3,2) (2,1.5) (4,2.8) (6,5)};
        \coordinate (A) at (-2.0, -0.9);
        \coordinate (AB) at (-0.4,+0.4);
        \coordinate (BB) at (-1.6,1.75);
        \coordinate (B) at (-1.4,0);
        \coordinate (C) at (0, 1.75);
        \coordinate (F) at (6.1, 4.75);
        \draw[thick] (A) .. controls (AB) and (BB) .. (F); 
        \node at (1.5,3.5) {$y=f(x)$};
        \draw [thick,dashed] (A) -- (F);
        \coordinate (yaxis) at (0,6);
        \coordinate (xaxis) at (6,0);
        \draw [->] (F) -| (xaxis -| F) node[above, yshift=0.5cm] {$x_R$};
        \draw [->] (A) -| (xaxis -| A) node[above, yshift=0.05cm] {$x_L$};
        \node at (-1.5, 2.2) (fa) {"falsi" next guess};
        \draw [->] ($(fa)+(-0.8,-0.25)$) -- ++(0,-.35cm) -- (-0.7,0);
        \node at (4.7, -1.25) (xarr) {$x\quad \xrightarrow{\hspace*{0.4cm}}$};
        % debug and helpers
        \iffalse
        \draw [blue, very thick] (A) circle (0.1);
        \draw [green, very thick] (BB) circle (0.1) node[anchor=north] {BB};
        \draw [green, very thick] (AB) circle (0.1) node[anchor=north] {AB};
        \draw [blue, very thick] (B) circle (0.1);
        \draw [blue, very thick] (C) circle (0.1);
        \draw [blue, very thick] (F) circle (0.1);
        \draw [red](-0.8,0) -- ++(0,0.5);
        \draw [xshift= 0.1cm, step=0.25,blue, very thick, opacity=0.2] (-2.5,-1.5) grid (6.5,6.5);
        \fi
    \end{tikzpicture}
    \caption{\textit{Graphical Illustration of regula falsi}}
    \label{fig:06_04}
\end{figure}

A straight line in the x-y plane has the analytic form
\begin{equation}
    y = ax + b
    \label{eq:06_11}
\end{equation}
where a and b are constants. The intercept of the straight line with the x-axis is gotten by setting y = 0 and solving for x:

\begin{equation}
x' = \frac{-b}{a}
\end{equation}

To determine a and b we use the two equations

\begin{equation}
f_L = ax_L + b
f_R = ax_R + b
\end{equation}

giving

\begin{equation}
a = \frac{1}{2}[f_L + f_R - \frac{f_R - f_L}{x_L + x_R} (x_L + x_R)
\end{equation}

and thus

\begin{equation}
x' = \frac{f_Rx_L - f_Lx_R}{f_R - f_L}
\end{equation}

A FORTH flow diagram for this algorithm appears in Fig. 6-5.

\begin{lstlisting}
INITIALIZE
f_L=f(x_L) f_R=f(x_R)
x_old = X_L
BEGIN calculate x’
|x' - x_old| > error
?
WHILE
f\hat = f(x')
sgn(f\hat) = sgn(f_L) ?
IF x_L = x f_L = f

ELSE x_R = x f_R = f

THEN

REPEAT
\end{lstlisting}

Fig. 6-5 Regula falsi algorithm for roots of f(x)

The corresponding program is shown on page 132.

Here is an example of the program in action:

\begin{lstlisting}
FINIT 6 #PLACE ! ok \ set display to 6 digits
\ Example: f(x) = exp(-x) - x
: FNA FDUP FNEGATE FEXP FR- ;
\ Cleariy, the root lies between 0 and 3. (Why?)

USE( FNA % 0. % .3 % 1.E-6 )FALSI
\ st(4) st(3) st(2)  x'      x'-xold
?????? ?????? ?????? .759452 -.291530
?????? ?????? ?????? .588025 -.0326025
?????? ?????? ?????? .569459 -.00362847
?????? ?????? ?????? .567400 -.000403560
?????? ?????? ?????? .567171 -.0000448740
?????? ?????? ?????? .567146 -.0000050002
?????? ?????? ?????? .567143 -.0000005544 ok
\end{lstlisting}

The display was generated by the word .FS --placed in the
definition of APART? for debugging -- we show the top 5 of the eight 80x87 registers. The ?????? means the contents of that register are not a properly defined fp number, either because of a mistake or because nothing was stored in them after FINIT. Here, since the program is obviously working, the latter explanation is the correct one.

Ordinary differential equations
We wish to solve the first-order general differential equation

\begin{equation}
x\dot = \frac{dx}{dt} = f(x,t)
\end{equation}

In general we can only solve Eq. 16 approximately, starting from the value of x -- call it $x_0$ -- at some initial time $t_0$, then advancing the time by small increments dt = h, using the differential equation itself to give us x(t+h) given x(t).

For example, we could expand in Taylor’s series\sepfootnote{06_11}

\begin{equation}
x(t+h) = x(t) + h\dot{x}(t) + \frac{h^2}{2}\ddot{x}(t) + ...
\end{equation}

\begin{lstlisting}
    \ USE( Fname % a % b % err )FALSI
    ( 87:--rooot )
    \ Fname is the name of a FORTH function

    \ function notation
    : USE( [COMPILE] ' CFA LITERAL ;
           IMMEDIATE

    6 REAL*4 SCALARS ERR XL XR YL YR OLDX

    0 VAR f1 \ a place to store cfa
    : SAME.SIGN? (87:xy -- -- f)
        F* F0> ;

    :INITIALIZE ( cfa -- 87: a  be -- )
        IS f1   \ stare cfa
        XDUP    \ interval has root?
        SAME.SIGN?
        ABORT" Even number of roots!!!"
        XR G! XL G!
        XL G@ f1 EXECUTE YL G!
        XR G@ f1 EXECUTE YR G!
        F=0 OLDX G! ;

    : X' XL G@ FR G@ ( 87: -- x')
        FUNDER F*    ( 87: -- yR xL *yR)
        XR G@ YL G@
        FUNDER F* ( 87: -- yR xL*yR xL xR*yL )
        FROT   F- ( 87: -- yR yL xR*yL -xL*yR)
        F-ROT  F- F/ ;

    : APART? ( 87: x' -- x' -- f )
        FDUP OLDX G@ F-
        .FS FABS ERR G@ F> ;

    : REVISE ( 87: x' -- )
        FDUP f1 EXECUTE ( 87: -- x' y')
        FDUP YL G@
        SAMESIGN? FOVER
        ( --f 87: -- x'y' x')
        IF      XL G! YL G!
        ELSE    XR G! YR G! THEN
        OLDX G! ; ( -- 87: -- )

    : )FALSI ( cfa-- 87: a b e -- root ) INITIALIZE ;
\end{lstlisting}

and keep only the lowest order terms:

\begin{equation}
x(t+h) \approx x(t) + hf(x(t), t).
\end{equation}

Runge-Kutta method

One standard class of methods that had fallen into disfavor by now are popular again, are the Runge-Kutta algorithms\sepfootnote{06_12}. The algorithms can be classified according to order n (that is, if h the step size, the error at each step will be $O(h^n)$. The second order Runge-Kutta algorithm is $(x' \equiv x(t+h) , x \equiv x(t) )$

\begin{equation}
k = hf(x,t)
x' = x + \frac{1}{2}(k + hf(x+k, t+h)) + O(h^3).
\end{equation}

How does this work? Clearly,

\begin{equation}
k + hf(x+k,t+h) \approx hf(x,t) + hf(x,t) + h^2\frac{\partial f}{\partial t} + hk \frac{\partial f}{\partial x}
\equiv 2h\dot{x}(t) + h^2\ddot{x}(t) + O(h^3)
\end{equation}

Substituting 19 in 20 we now find

\begin{equation}
x' = x(t+h) = x(t) + h\dot(t) + \frac{h^2}{2}\ddot{x}(t) ;
\end{equation}

that is, the Runge-Kutta x' agrees with the Taylor's series expansion 17, to $O(h^3)$.

The flow chart of second-order Runge-Kutta is shown in Fig. 6.6 below. We express the algorithm in FORTH as shown in Fig. 6-7 on page 134 below.

\begin{lstlisting}
)RUNGE
INITIALIZE: get h, tf, t0, x0

BEGIN DISPLAY
    DONE? NOT
WHILE
    STEP
REPEAT
\begin{lstlisting}

Fig. 6-6 2nd-order Runge-Kutta for dx/dt = f(x,t)

\begin{lstlisting}
    \ STRAIGHT 2ND ORDER RUNGE-KUTTA
    \ SOLUTION OF FIRST-ORDER DIFEQ
    \ dx/dt = f(x,t)

    \ See Abramowitz & Stegun, HMF 25.5.6

    \ Usege:
    \ USE( FNB % x0 % t0 % tf % h )RUNGE
    \
    \ FNB (:[t]-- 87:x--f[x,t]) evaluates f(x.t)
    \ x0 = starting value of dep. variable
    \ t0 = initial time
    \ tf = end time
    \ h = step.size
    \
    \ k = hf(x,t), x' = x + (k +hf(x+k,t+h))/2

    6 REAL*4 SCALARS T T' H X TMAX K
    0 VAR f1 \ to hold cfa
    : USE( [COMPILE]' CFA LITERAL;
           IMMEDIATE
    : INITIALIZE (:cfa-- 87: x0 t0 tf h -- )
        IS f1 H G! TMAX G! T G! X G! ;

    \ These words increment x & t.
    : inc.T     T G@ H G@ F+ T' G! ;
    : inc.X     X G@
             T  f1 EXECUTE (87:--f[x,t])
             H  G@ F*      (87:--k=hf[x,t])
             FDUP K G!    \ save k
             X  G@ F+      (87:-- x+k)
             T' G@ T G!
             T  f1 EXECUTE (87:--f[x+k,t+h])
             H  G@ F*
             K  G@ F+ F2/
                           (87:--[k+i[x+k,t+h] ]/2)
             X  G@ F+ X G! ;

    : DONE? TG@ TMAXG@ F>) ; (:--f)

    0 VAR exact            \ cfa
    : DISPLAY   exact EXECUTE
        XG@  T  G@ CR F. F. F. ;
    \ emit "t x exact”

    : )RUNGE               (:cfa-- 87: x0 t0 tf h -- )
            BEGIN DISPLAY
                    DONE? NOT
\end{lstlisting}
Fig. 6-7 Explicit 2nd-order Runge-Kutta solver

As an example of second-order Runge-Kutta in action, let us solve numerically the equation ,

\begin{equation}
\dot{x} = t^2 e^-x
\end{equation}

with the initial condition x(t = 0) = 0 , whose exact solution is

\begin{equation}
x(t) =log_e(1 +\frac{1}{3}t^3).
\end{equation}

t x h. t x 1.
Big List

Fig. 6-8 Second order Runge-Kutta - results

Thus define

\begin{lstlisting}
: FNB (:[T]-- 87: x--f[x,t])
    FNEGATE FEXP G@ F**2 F*
: EXACT T G@ FDUP FDUP F* F* (87:--t^3)
    3 S->F F/ F=1 F+ FLN ;
\end{lstlisting}

and say

\begin{lstlisting}
USE( EXACT IS exact ok
USE( FNB % 0. % 0. % 5. % 0.1 )RUNGE
\end{lstlisting}

The resulting output is shown in fig. 6-8 above.

\subsection{An implicit Runge-Kutta formula}
\TallC{A variation} on straight Runge-Kutta is a so-called implicit algorithm\sepfootnote{06_13}.For example, in the second-order formulae given above, suppose x + k were replaced by x’:

\begin{equation}
k = hf(x,t)
x’ = x + \frac{1}{2}(k + hf(x',t+h)) + O(h^3)
\end{equation}

and the resulting (transcendental) equation solved for x’ by --say-- regula falsi. Since we have already written a regula falsi program, we can apply it here to get the algorithm shown diagrammatically in Fig. 6-9 below. We program it\sepfootnote{06_14} as shown in Fig. 6-10 on page 137 below.

)RUNGE
  INITIALIZE: get h, tf, t0, x0

  BEGIN DISPLAY
   DONE? NOT
  WHILE
   k=hf(x,t)
    SOLVE: x' = x + k/2 +hf(x’,t+h)/2
  REPEAT

Fig. 6-9 2nd-order implicit Runge-Kutta for dx/dt = f(x,t)

Now we consider the same example as previously:

\begin{lstlisting}
: FNB (:[T]-- 87:x--f[x,t])
    FNEGATE FEXP G@ F"2 F' ;
: EXACT T G@ FDUP FDUP F* F* (87: -- t^3)
    F=3 F/ F=1 F+ FLN ;
\end{lstlisting}

and say

\begin{lstlisting}
USE( EXACT IS exact ok
USE( FNB % 0. % 0. % 5. % 0.1 )RUNGE ok

FIND )FALSI 0= ?( FLOAD FALSI.FTH)
7REAL*4 SCALARS T T' H X X' TMAX K
0 VAR f1    \ to hold cfa of f(xt)
: INITIALIZE IS f1
        H G! TMAX G! T G! X G! ;

\ These words Increment x & t.
: inc.T T G@ H G@ F+ T' G! ;
: k     X G@
    T f1 EXECUTE   ( 87:--f[x,t])
    H G@ F* K G! ; ( 87:--k=hf(x,t)

: X" ( 87:x'--g[x’])
    T f1 EXECUTE   ( 87:--f[x',t+h])
    H G@ F* K G! F+ F2/
     ( 87:--[k+f[x+k,t+h] ]/2)
    X G@ F+ ;

% 3. FCONSTANT F=3
:INTERVAL X G@ FDUP
       K G@ F=3 F* F+ ;

: X' USE( X" INTERVAL % 1.E-6
       )FALSI ;
: inc.X k X’ X G! T' G@ T G! ;
: DONE? T G@ TMAX G@ F> ;
      (:--f)
0 VAR exact         \ cfa
: DISPLAY exact EXECUTE
    X G@ T G@ CR F. F. F. ;
\ emit "t x exact"
: )RUNGE (:cfa--87:x0 t0 tf h -- )
    BEGIN DISPLAY
\end{lstlisting}

Fig. 6-10 Implicit 2nd-order Runge-Kutta program

The resulting output is shown in Fig. 6-11 on page 138.

Clearly the implicit form is more accurate; whether the putative gain in stability justifies solving a transcendental equation is unclear, however.

$t X X_ex t X X_ex$
Big List

Fig. 6-11 Second order implicit Runge-Kutta - results

Let us now compare the two algorithms for functions f(x,t) that lead to singular solutions. This time we consider the equation

\begin{equation}
\dot{x} = t^2e^x
\end{equation}

whose exact solution is

\begin{equation}
x(t) = -log_e(1-\frac{1}{3}t^3).
\end{equation}

Manifestly, 25 blows up at $t = 3^\frac{1}{3}=1.442...$ We expect the behavior to become apparent in the numerical solution. So we say

\begin{lstlisting}
: FNB FEXP G@ F**2 F*;
    ([t] -- 07: x --i[x,t])

: EXACT F=1 T G@ (87:--t^3)
    FDUP FDUP F* F* F=3 F/ F+ FLN ;
\end{lstlisting}

and say again
\begin{lstlisting}
USE( EXACT IS exact ok
USE( FNB % 0. %0 % 5. % 0.1 )RUNGE ok
\end{lstlisting}

The results of doing this with straight-, and then implicit Runge-Kutta are displayed in Fig. 6-12 (p. 140) and 6-13 (p. 141), respectively. We only show the second half of the interval (near the singular point) in either case.

The straight Runge-Kutta algorithm, without the fancy implicit solution for $x(t +h)$, appears more accurate near the singularity, although both methods are acceptably accurate. Does this mean implicit Runge-Kutta is no good? No!

The implicit scheme lost accuracy through roundoff: the arithmetic was insufficiently precise. To take advantage of the method’s power, we must increase the precision beyond one part in $10^{6}$. This requires changing all scalars to 64-bit precision (\regc{REAL*8}) rather than 32-bit as we have done here. The generic fetch/store techniques developed in Chapter 5 and used here, permit this change with a minimum of fuss. We leave this as an exercise.

$t X X_EX t X X_EX$
Big list

Fig. 6-12 \textit{Straight Runge-Kutta for singular case}

Fig. 6-13 \textit{Implicit Range-Kym for singular case}
