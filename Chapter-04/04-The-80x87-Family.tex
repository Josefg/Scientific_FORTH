\chapter{The 80x87 Family}
\startcontents[chapters]
\printcontents[chapters]{}{1}{}

\TallC{W}{hen} we speak of the 80x87 mathematical co-processor family, we include the original Intel chips, the Cyrix D387 and HT C287 and C387 chips, and the AMD 80287 and 80387 clones, as well as the on-chip floating point unit found on the Intel 80486 chips.

We now describe some features of the 80x87 floating point co-processors (FPUs) that affect scientific programming on IBM-PC compatible machines\footnote{Although we confine ourselves to the 80x87 chip, the Motorola 68881/2 coprocessors can be programmed in  the same general manner to achieve floating point capabilities rivialling VAX minicomputers.}. The 8087 chip complements the Intel 8088/8086 CPU family, the 80287 works with the 80286 series, the 80387 with the 80386, and the 80486 includes an on-chip FPU. The 8087 chip is connected pin-for-pin to the 8088/8086. (The details are given in \textit{The 8087 Primer\footnote{J. Palmer and S. Morse, \textit{The 8087 Primer} (John Wiley & Sons, NY (1984), hereafter referred to as \textbf{8087P}).} The interface and instruction set automatically take care of bus arbitration (that is, which chip has access to the memory) and interrupts, in order to be sure that the CPU and 80x87 do not perform conflicting operations.

Instructions for the 80x87 are always appended to a code called “escape” (ESC, D8h) that alerts the coprocessor and diverts control to it. The MS-DOS assembler MASM and debugger DEBUG will automatically assemble this code with 80x87 instructions, so the user does not need to worry about including ESC except to be aware that it is happening. (Of course, a FORTH system that lacks 80x87 assembler extensions will need to include ESC explicitly to generate 80x87 codes.)

We shall see in Ch. 4 §1.1 how to use the FORTH assembler, and in Ch. 4 §1.2 how to use DEBUG\footnote{A treasure included with MS-DOS}, to extend a FORTH system for 80x87 operations if they are not already included as a floating point lexicon.

The 80x87 machine code instruction set includes instructions for moving numbers to the registers from memory and vice-versa, as well as from one 80x87 register to another. The internal moves are of course much faster than those to or from external memory.

Advanced programming methods — such a recursive algorithms — require an fstack of unlimited depth. The designers of the 8087 anticipated the need for fstack extension and included instructions for this purpose. Unfortunately, the instructions were not well thought out\footnote{see \textbf{8087P}, p. 93ff.} so a moderately complex software fstack extension manager is needed to augment them. We design such a manager in Ch. 4 §7.

\section{Internal 80x87 and manipulation}

The 80x87 is organized around a stack of 8 80-bit registers (the87stack). The 8-deep stack can be subdivided into smaller stacks for special purposes, but this is only useful when coding in assembler for speed\footnote{see \textbf{8087P, p. 87ff.}.

We begin with words for performing 80x87 stack manipulation analogous to those defined for parameter stack. These are \bc{FDUP FSWAP FDROP FROT FOVER} .

How are we to define them in terms of machine code primitives?

\subsection{The FORTH assembler}

\TallC{E}{very} FORTH worthy of the name includes an assembler, usually set up as an alternate vocabulary\footnote{Vocabularies are a method for subdividing the dictionary.} called \bc{ASSEMBLER}. The assembler allows direct definition of a new word in terms of machine codes, which are referred to using standard mnemonics. A typical FORTH assembly language definition (we now specialize to HS/FORTH) for @ would have the form\footnote{BX is a CPU register, and \[BX\] means "the memory location wose address is in BX". HS/FORTH uses a naming convention in which assembler mnemonics end with a period, \textit{e.g.} MOV, . Also, HS/FORTH makes the TOS the BX register, to reduce the number of pushes and pops needed to execute simple words.}

\begin{listing}
    CODE @ BX [BX] MOV. END-CODE
\end{listing}

A \bc{CODE} definitionis a machine-coded subroutine somewhere in memory. To use it, the compiler has to know where it is and insert appropriate unconditional JUMP (JMP) and RETURN (REI‘) instructions in the machine code representation of the calling program.

Here is what happened in the \bc{CODE} version of \regc{@} above:

\begin{list}
    \item The defining word \bc{CODE} set up a dictionary entry with the name \bc{@}, with an appropriate pointer and JUMP instructions to make the newly defined word run the code sequence comprising the definition.
    \item The word \bc{END-CODE} cleans up the loose ends by adding the obligatory RET instruction sequence and turning off the compiler. (That is, \bc{END-CODE} installs “\bc{NEXT}".)
    \item \bc{END-CODE} is thus the analog of \bc{;} as \bc{CODE} is of \bc{:}.
\end{list}

Consider now the word \bc{FROT} whose Intel assembly language definition would be

\begin{listing}
    FROT:       ; entry point
    FWAIT       ; hold 8086 operations
    FXCH ST(1)  ; swap TOS and NOS
    FWAIT       ; hold 8086 operations
    FXCH ST(2)  ; swap TOS and ST(2)
    RET         ; return
\end{listing}

In HS/FORTH assembler, the definition becomes

\begin{listing}
    CODE FROT FWAIT. 1 FXCH. FWAIT. 2 FXCH.
        END-CODE
\end{listing}

\leftbar[1\linewidth]
\textbf{\textunderline{Note}: the definition includes \regc{FWAIT} (the same as \regc{WAlT}), an instruction that makes the 8086 CPU wait for the FPU to complete its work before attempting to access the memory. If \regc{WAlT} were omitted and the CPU accessed the memory, it could store incomplete resultss.
\endleftbar \footnote{The design of the 80286, 80386, and 80486 eliminates this problem. consequently \regc{FWAIT} is not required when assembling 80287/80387/80487 machine code. See, \textit{e.g.}, John H. Crawford and Patrick P. Gelsinger, \textit{Programming the 80386} (Sybex. San Francisco, 1987). HS/FORTH allows the user to choose which class of machine to assemble for, when loading the 80x87 assembler extension. The 80287+ option simply defines \regc{FWAIT.} as a null word.}

subsection{Using MS-DOS DEBUG}

\TallC{T}{he} FORTH assembler, with its 80x87 extension, lets us develop machine-coded words while retaining Intel mnemonics for documentation, at the price of loading and compiling the entire \bc{ASSEMBLER} lexicon. But if we know the actual machine code bytes we can bypass the assembler by entering the (hexadecimal) codes directly into a \bc{CODE} definition. Most FORTH system, in addition to an assembler, provide a way to insert machine codes - hex numbers - directly into the code field of a word. HS/FORTH, \texit{e.g.}, uses the words <% and %> to enclose the hex codes being inserted.

The problem is, how do we find out what these hex codes are?

The simplest way is to use DEBUG\footnote{see, \eg, R. Lafitte, \textit{Assembly Language: Primer for the IBM PC & XT} (Plume/Waite-New American Library, New York, 1984). Complete operating systems often include a code debugger that permits assembly; disassembly; modifying the contents of selected memory locations; setting breakpoints; and running proyams under debuger control.} to generate (HEX) code sequences. Rather than try to explain, we shall illustrate by recording and annotating the DEBUG session for the word \bc{FROT}:

\begin{listing}
    C > DEBUG               starts DEBUG
    -A100                   Assemble from 100h
    3B01:0100 FWAIT         enter asembler
    3B01:0101 FXCH ST(1)    mnemonlcs
    3B01:0103 FWAIT
    3B01:0104 FEXCH ST(2)
             ^ Error        DEBUG notes a typo
    3B01:0104 FXCH ST(2)
    3B01:0106       no more, <cr>stops assembly
    
    -U 100 105              Unassemble to check
    3B01:0100 9B    WAIT    Hold CPU
    3B01:0101 D9C9  FXCH    ST(1)
                            (87: a b c -- a c b )
    3B01:0103 9B    WAIT    Hold up CPU
    3B01:0104 D9CA  FXCH    ST(2)
                            (87: a c b -- b c a)

    -D 100 105              Dump to get hex codes
    3B01:0100 9B D9 C9 9B D9 CA
    -Q                      Quit session
\end{listing}

From the \underline{D}ump (or \underline{U}nsassembly) we find code bytes 9B D9 F7 D9 C9 F6 D9 C9 which can be inserted directly into the definition of \bc{FROT}:

\begin{listing}
    CODE FROT <% 9B D9 F7 D9 C9 F6 D9 C9 %>
        END-CODE (:: a b c -- b c a )
\end{listing}
The rest of the 80x87 stack words,
\begin{listing}
    FDUP FSWAP FDROP FOVER F-ROT
\end{listing}

whose assembler definitions are:
\begin{listing}
    CODE    FDUP      FWAIT. 0  FLD.  END-CODE
    CODE    FSWAP     FWAIT. 1 FXCH.  END-CODE
    CODE    FDROP     FWAIT. 0 FSTP.  END-CODE
    CODE    F—ROT   FWAIT. 2 FXCH.
            FWAIT.  1 FXCH.           END-CODE
\end{listing}

can be defined similarly in 8086/8087 machine code using the
DEBUG program or a reference manual for the chip (\eg \textbf{8087P})to determine the hex codes.

\section{Memory usage (storage and retrieval)}

\TallC{T}{he} 80x87 instruction set includes codes for loading \regc{ST (0)} from memory and storing \regc{ST(0)} to memory. The former involeves a "push" and the latter may or may not involve a "pop", from
the 87stack.

For the moment we need words to retrieve and store 16-bit integers, short reals (32 bit) and temporary reals (80 bit). These have mnemonics \regc{FILD} ("load integer to \regc{ST (0)}"), \regc{FISTP}("store integer and pop \regc{ST(1)} into \regc{ST(0)"); \regc{FLD}, \regc{FSTP} respectively. Typical (HS/)FORTH assembler definitions are

\begin{listing}
    CODE I16@
        FWAIT. [BX] WORD-PTR FILD.
        [BX] POP.
        FWAIT.
    END-CODE
    CODE |16|
        FWAIT. [BX] WORD-PTR FISTP.
        [BX] POP.
        FWAIT.
    END-CODE
\end{listing}

Similarly, \bc{I32@} and \bc{I32!} can be defined by replacing \bc{WORD-PTR} with \bc{DWORD-PTR}. To define \bc{I64@} and \bc{I64@} -assuming these are needed— replace \bc{DWORD-PTR} with \bc{QWORD-PTR}. The 32-, 64-, and 80-bit floating point analogues \bc{R32@}, \bc{R32!}, \bc{R64@}, \bc{R64@}, \bc{R80@}, and \bc{R80!} are defined byreplacing \bc{FILD} by \bc{FLD} and \bc{FISTP} by \bc{FSTP}, and using \bc{DWORD-PTR}, \bc{QWORD-PTR} or \bc{TBYTE-PTR}\footnote{"Ten-byte pointer". Note HS/FORTH appends a period "." to most Intel mnemonics.} as appropriate.

\TallC{W}{e} also need words to load the 87stack from the stack and textit{vice versa}. In HS/FORTH, the top of the parameter stack is actually the BX register on the CPU. There is no machine instruction for loading the 87stack directly from a CPU register. Thus, we must first transfer the contents of BX to memory and thence to the 87stack. The inverse operation also must proceed through a memory location. The data-transfer words are named in an obvious way \bc{S->F} and \bc{F->S}. HS/FORTH defines them directly in machine code, manipulating the CPU register BP that points to the top of the CPU stack. That is, HS/FORTH uses two bytes immediately below NOS as the intermediate memory cell.

Here we define \bc{S->F} and \bc{F->S} directly in high-level FORTH by wasting a little memory for a (hidden) temporary variable:

\begin{listing}
    VARIABLE TEMP
    : S—>F (n-- ::--float[n])
        TEMP !          \TOS —> TEMP
        TEMP I16@ ;     \TEMP-> ST(O)
    : F—>S (::x — --int[x])
        TEMP I16!       \ST(O) -> TEMP
        TEMP @ ;        \TEMP—> TOS
    BEHEAD' TEMP        \ hide address of TEMP
\end{listing}

Faster machine code versions of \bc{S->F} and \bc{F->S} are\footnote{\bc{TEMP + []} is HS/FORTH's phrase to assemble a named memory address.}

\begin{listing}
    CODE S—>F TEMP +[] BX MOV. BX POP.
        FWAIT. TEMP +[] I16 fiLD. END-CODE

    CODE F—>S BX PUSH. TEMP +[] FISTP.
        BX TEMP +[] MOV. END-CODE
\end{listing}

These definitions will satisfy our present needs for storing and retrieving from the 87stack.

\leftbar[1\linewidth]
\Note: a substantial gain in speed can be achieved with the
80386/80387 and 80486 families, by using instructions that effect
32-bit wide transfers.
\endleftbar \footnote{See, \eg, John H. Crawford and Patrick P. Gelsinger, \textit{Progumming the 80386} (Sybex, San Francisco, 1987).}

\section{Arithmetic words}

\TallC{F}{PU} (80x87) arithmetic is generally performed with the maximum precision allowed by the (80-bit) size of the registers\footnote{Although it \textit{is} possible to force artificially 80x87 precision to 24 mantissa bits to simulate arithmetic performed on other machines (that is, to compare results while debugging), I see no virture in a mode that shows up calculations while \textit{diminishing} precision and refer the reader to refs. 2 or 8.}.

As noted in §4.2, the 80x87 allows 3 floating point representations
for storage and retrieval in external memory: 32 hit (single precision),
64 bit (double precision) and 80 bit (“temporary real”).

To conserve memory we generally use 32 bit floating point num-
bers (REAL'4 in the old FORTRAN parlance)unless the nature
of the calculation demands retention of more significant figures
to prevent roundoff errors.

The FORTH arithmetic words we shall need are

F+ F— FR— F* F/ FR/ FNEGATE FABS FSGN
whose definitions are (CODE and END-CODE are assumed)

\begin{listing}
    F+      FWAIT.    FADDP.    (87: a b -- a+b)
    F-      FWAIT.    FSUBP.    (87: a b -- a—b)
    FR-     FWAIT.    FSUBRP.   (87: a b -- b—a)
    F*      FWAIT.    FMULP.    (87: a b -- a'b)
    F/      FWAIT.    FDIVP.    (87: a b -- a/b)
    FR/     FWAIT.    FDIVRP.   (87: a b -- b/a)
\end{listing}

\begin{listing}
    FNEGATE FWAIT.  FCHS.   (87: a -- -a)
    FABS   FWAIT.   FABS.   (87: a -- |a|)

    : FSGN      (n-- 87:x -- |x|*sgn[n])
        FABS 0< IF FNEGATE THEN ;
\end{listing}

\section{Special constants}

\TallC{F}{or} convenience the designers of the 8087 chip have arranged fast loading of certain constants into \bc{ST(0)} of the fstack (TOS). The words that place these constants on the fstack, and the corresponding assembler mnemonics and (hex) codes are shown in Table 4-1 below.

Table 4-1 Speclal Constants
\begin{center}
    \begin{tabular}{|c c c c|}
        word      & const.      & mnemonic  & codes     \\
        F=0       & 0           & FLDZ      & 9B D9 E5  \\
        F=1       & 1           & FLD1      & 9B D9 E8  \\
        F=PI      & pi=3.14...  & FLDPI     & 9B 09 E5  \\
        F=L2(10)  & log_{2}10   & FLDL2T    & 9B D9 E9  \\ 
        F=L2(E)   & log_{2}e    & FLDL2E    & 9B 09 EA  \\
        F=L10(2)  & log_{10}2   & FLDLG2    & 9B 09 EC  \\
        F=LN(2)   & log_{e}     & FLDLN2    & 9B 09 ED  \\
    \end{tabular}
\end{center}

\section{Test words}

\TallC{W}{e} need to be able to determine the algebraic sign of a floating point number, as well as whether one is larger than another.
The 80x87 chip has 4 instructions for this purpose, whose mnemonics are FTST, FCOM, FCOMP and FCOMPP; they are shown below in Table 4-2.

Table 4-2 \textit{Machine language floating point tests}
\begin{center}
    \begin{tabular}{|c c c|}
        mnemonic    &   comparison      &   pop?        \\
        FTST        &   ST(O) to 0      &   no          \\
        FCOM        &   ST(1) to ST(O)  &   no          \\
        FCOMP       &   ST(1) to ST(O)  &   pop once    \\
        FCOMPP      &   ST(1) to ST(O)  &   pop twice   \\
    \end{tabular}
\end{center}

The results of these comparisons are encoded as bits C3 (14) and C0 (8) of the 16-bit 80x87 STATUS register. In order to get these bits by bit-masking techniques the STATUS register must be moved to the parameter stack\footnote{\Note: the 80387 includes a new instruction whereby the status control word can be moved \textit{directly} into the AX register of the 80386 CPU. The hex codes for FSTSW AX are DF E0.}. This is done with the the 80x87 instruction \regc{FSTSW} \textit{via} the assembler sequence

\begin{listing}
    VARIABLE F.STATUS
    CODE FSTSW BX PUSH.
        F.STATUS +[] FSTSW.
        BX F.STATUS +[] MOV.
    END-CODE
    BEHEAD' F.STATUS
\end{listing}

Now we have to consider how to bit-mask the status integer left on the stack by FSTSW. We use the logical AND with 400011 og 0100h (\textunderline{Exercise}: Why?) to pick out C3 and C0. Now from \textbf{8087P}\footnote{see, \eg, Table 4.1} we have the truth table 4-3 below:

\begin{center}
    \begin{tabular}{|c c c|}
        \textbf{Conamon}    &   \textbf{C3} & \textbf{C0}   \\
        ST(0) > x           &   0           & 0             \\
        ST(0) = x           &   1           & 0             \\
        ST(0) < x           &   0           & 1             \\
    \end{tabular}
\end{center}

Now we are in a position to define the test words \bc{F0>}, \bc{F0=},
\bc{F0<}, as well as \bc{F>}, \bc{F=}, \bc{F<} .We have\footnote{\Note the test worrds \bc{F<} and \bc{F>} are defined opposite to \bc{F0>} and \bc{F0<}. This reversal of directions is \textit{not} a typographical error: it is \textit{demanded} by the operation of \bc{FCONPP} -see \textbf{8087P}.}

\begin{listing}
    CODE FTST FWAIT. FTST. 0 FSTP END-CODE
    CODE FCOMPP FWAIT. FCOMPP. END-CODE

    HEX
    : FTSTP FTST FSTSW ;
    : F0> FTSTP 4100 AND NOT 0) ;
    : F0= FTSTP 4000 AND 0> ;
    : F0< FTSTP 0100 AND 0> ;
    : F< FCOMPP FSTSW 4100 AND NOT 0> ;
    : F= FCOMPP FSTSW 4000 AND 0> ;
    : F> FCOMPP FSTSW 0100 AND 0> ;
    DECIMAL
\end{listing}

\section{Mathematical functions}

\TallC{W}{e} now proceed to develop a suite of special functions for the 801187 FPU. These will include the usual trigonometric functions, logarithms, and exponentials. We retain initial Fs' 1n the names to remind us the FPUis being used. The functions are given in Table 4-4 below:

Table 4-4 Mathematical function primitives

\begin{center}
    \begin{tabular}{|c c c c|}
        \textbf{name}   &   \textbf{action}             & \textbf{code(s)}  & \textbf{mnemonic} \\
        FSQRT           &   (87: x -- \sqrt{x})         & 9B D9 FA          & FWAIT FSQRT       \\
        FY*LG2X         &   (87: y x -- y*log_{2}[x])   & 9B D9 F1          & FWAIT FYL2X       \\
        FY*LG2XP1       &   (87: y x -- y*log_{2}[x+1]) & 9B D9 F0          & FWAIT FYL2XP1     \\
        F2XM1           &   (87:x-- 2^{x}-1)            & 9B D9 F0          & FWAIT F2XM1       \\
    \end{tabular}
\end{center}

These primitive functions allow us to define the logarithms and exponentials. To get $log_{2}(x)$, for example, we need to decide whether $x$ lies between 0 and 2: this can best be accomplished with
the sequence (we assume $x$ is already on the 87stack)

\begin{listing}
    : F=2 F=1 FDUP FSCALE FPLUCK ; (e7:--2)(*@\footnote{See below for a discussion of \bc{FSCALE}.}@*)

    : LOG.TST FDUP F0> NOT
       ABORT" Can't take log(—|x|) 11" ;

    : FLG (87: y x -- y*lg[x])
        LOG.TST  FDUP F=2 F<
        IF      F=1  F- FY*LG2XP1
        ELSE    FY*LG2X THEN ;

    : FLN   F=LN(2)     FSWAP FLG ;
    : FLOG  F=L10(2)    FSWAP FLG ;
\end{listing}

Now we can use the fundamental definition of exponentiation to define both the operation of raising an arbitrary positive number to a real power, as well as the standard mathematical function $e^x$:

\begin{listing}
    : F2**  (87: x   -- 2**x)   F2XM1 F=1 F+ ;
    : F*    (87: x y -- y**x)   FLG F2** ;
    : FEXP  (87: x   -- exp[x]) F=L2(E) F* F2** ;
\end{listing}

\TallC{W}{e} now have only to implement the trigonometric and inverse-trigonometric functions. We need (TREAL) IO-byte constants:

\begin{listing}
    : F,        HERE    10 ALLOT R80! ;
    : FCONSTANT CREATE  F, DOES> R80@ ;
\end{listing}

Also, for simplicity, we define FORTH functions for degree/radian conversions and conversely:

\begin{listing}
    : FINIT     F=PI    180 S->F F/    (87:-- p/180)
    : FCONSTANT PI/180                \ make constant
    : DEG->RAD  PI/180 F* ;
    : RAD->DEG  PI/180 F/ ;
\end{listing}


The 80x87 chip has a fast way to multiply or divide by powers of 2, called \bc{FSCALE}. The \bc{CODE} definition is

\begin{listing}
    CODE FSCALE <% 9B D9 FC %> END-CODE
\end{listing}

\bc{FSCALE} adds \regc{ST(1)} to the (powers-of-2) exponent of \regc{ST(0)}. Thus, \eg, we can write fast divide-and multiply-by-2 instructions:

\begin{listing}
    : F2* F=1 FSWAP         FSCALE  FPLUCK ;
    : F2/ F=1 FNEGATE FSWAP FSCALE  FPLUCK ;
\end{listing}

Now, according to \textbf{8087P}, we may evaluate trigonometric and inverse-trigonometric functions using the instructions

\begin{listing}
    CODE FPTAN  FWAIT. <% D9 F2 %> END-CODE
    CODE FPATAN FWAIT. <% D9 F3 %> END-CODE
\end{listing}

The 8087 and 80287 implement an \textit{unnormalized} tangent function, whose effect is \regc{(87: z -- y x)}, with $tan(z)=y/x$. Let us define

\begin{align} 
    \frac{y}{x} = tan(\frac{z}{2})
\end{align}

That is, we obtain the tangent of half the angle. The other trigonometric functions can be computed in software using the identities

\begin{align}
    sin(z) = \frac{2(\frac{y}{x})}{1 + (\frac{y/x})^{2}
    cos(z) = \frac{1 - (\frac{y}{x})^2}{1 + (\frac{y}{x})^2}
    tan(z) = \frac{sin(z)/cos(z)}
\end{align}

A further problem created by the 8087/80287 instruction set is that the argument $z$ must lie in the range $0 < z < \pi/4$. Thus we must shift the argument to this range, using a special instruction \bc{FPREM} ("exact" partial remainder\footnote{see \textbf{8087P}, p. 100ff}) that can be used to extract multiples of $\pi$:

\begin{listing}
    CODE FPREM FWAIT. <% D9 F8 %> END-CODE
    : XDUP FOVER FOVER ;
    : ENUF? FSTSW 1024 AND 0= ;     \ bit C2 =0?
    : FNORM (87: x k -- x mod k ) FSWAP
        BEGIN FPREM ENUF? UNTIL FPLUCK ;
        \ extract multiples of k
\end{listing}

Here is how we code the tangent in high-level FORTH:

\begin{listing}
    (*@
    \textbf\textunderline{Pseudocode version}:
    x=0 is an exception - set tan =0 and exit.
    x < 0 ? Save sign as a flag on stack.
    reduce by multiples of $\pi$
    x in 1st quadrant $\(\pi/2 < x < \pi )$ ? Flag, reduce by $\pi/2$
    x in 1st octant   $\(\pi/2 < x < \pi )$ ? Flag, reduce by $\pi/4$
    @*)
    
    

\ HIGH LEVEL FORTH VERSION
    : REDUCE ( :87: x k -- x mod k -- f)
       XDUP F> DUP IF F- ELSE FDROP THEN ;
    : FTAN   ( 87: x -- tan[x] ) FDUP F0=:
       IF EXIT THEN             \ tan=0
        FDUP F0< FABS           ( -- fsgn 87: -- |x| )
        F=PI FNORM              \ 0 < x < (*@$\pi$@*)
        F=PI F2/     REDUCE     ( -- fsgn f1q )
        F=PI F2/ F2/ REDUCE     ( -- fsgn f1q f1o )
        FPTAN fl (87: |x|— -tan[x])
        IF F=1 XDUP F+ F-ROT F- F/ THEN
                        \ adjust for octant
        IF 1/F FNEGATE THEN     \ adjust for quadrant
        IF FNEGATE THEN ;       \ adjust sign
\end{listing}

The remaining trigonometric functions (sine, cosine, scant, co-secant) can easily be defined in terms of $tan(z /2)$. For example, here are \bc{FSIN} and \bc{FCOS}:

\begin{listing}
    : FSIN F2/ FTAN FDUP FDUP F* F=1 F+
       FR/ F2* ;
    : FCOS F2/ FTAN FDUP F* F=1 FOVER F-
       FSWAP F=1 F+ F/ ;
\end{listing}

\leftbar[1\linewidth]
\Note: The 80387 improves on the 8087/80287 by eliminating the
need to adjust the argument in software. Further, the tangent
produced by the 80387 is normalized (that is, $x = 1.0$ in Eq. 4.1
above). finally, the 80387 has instructions \regc{FSIN}, \regc{FCOS and \regc{FSINCOS} built in, so all the software emulation is unnecessary.
\endleftbar

\TallC{W}{e} define inverse-trigonometric functions using \bc{FPATAN} defined previously, whose action is \regc{( 87: y x -- arctan[y/x] )}. The 80387 has no additional instructions for inverse trig functions, relative to the 8087/80287, so the same code fits all.

To calculate the inverse functions, we make use of standard identities (the forms chosen minimize roundoff error). Thus,

\begin{align}
    Arcsin(z) = Arctan\left(\frac{z}{\sqrt{(1-z)(1+z)}}\right)
    Arccos(z) = 2 Arctan\Big\{\left(\frac{1-z}{1+z}\right)^{\frac{1}{2}\Big\}
\end{align}

\begin{listing}
    : FATAN F-1 FPATAN ;
    : FASIN FDUP FABS F=1 F>
        ABORT' argu'nentotarcsh > 1'
        F=1 FOVER FDUP F* F- FSQRT
        F/ FPATAN ;

    : FACOS FDUP FABS F=1 F>
        ABORT" argument of arcsin > 1"
        FDUP F=1 FR- FSWAP F=1 F+ F/
        FSORT FPATAN ;
\end{listing}

\leftbar[1\linewidth]
\Note: the argument of arcsin($x$) or arccos($x$) must be smaller than
1 in absolute value - hence we include a bounds check to avoid taking the square root of a negative number.
\endleftbar

\section{Extending the intrinsic 80x87 stack}
\TallC{A}{s} promised' in the beginning of the chapter, we now design
a fstack manager in software that allows more than 8 cells. First we examine the structure of the 80x87 stack (\textbf{87stack}).

From \textbf{8087P} we see that the 8 registers in the 87stack are organized as a circular stack. A 3-bit pointer, \regc{ST}, records which physical register is actually TOS. The instruction set allows \regc{ST} to be incremented (\regc{FINCSTP}) or decremented (\regc{FDECSTP} modulo 8. The 87stack is shown below in Fig. 4-1 on page 81.

A \regc{FLD} instruction decrements \regc{ST} (mod 8) before storing whereas a \regc{FSTP} instruction increments \regc{ST}. To build our software fstack we need to do the following things:
\begin{itemize}
    \item When the 87stack gets full, put \regc{ST(7)} on the memory extensions and textit{vice-versa}.
    \item Keep track of how many numbers are on the 87stack.
    \item Keep track of where we have stored the last number removed from the 87stack.
\end{itemize}

\begin{listing}
0 4'TH FROM TOP
1 5'TH FROM TOP
2 6'TH FROM TOP
3 7'TH FROM TOP
4 0'TH FROM TOP
5 1'ST FROM TOP
6 2’ND FROM TOP
7 3'RD FROM TOP
fig. 4.1 The 00:87 snack. from seen:
\end{listing}

The algorithm has the following expression in pseudo-FORTH

\begin{listing}
    Redefine operations that put #5 on 87stack:
    increment stack _pointer
    it 87steck full put st(7) on fstack
    push onto st(O)

    Redefine operations that take #5 off 87stack:
    popst(0) _
    decrement stack _pornter
    iffstack notempty. puttofs onto st(7)
\end{listing}

We begin by defining the data structure (the fstack proper) where we will stash and retrieve the numbers coming off the 87stack.

\begin{itemize}
    \item We need to decide how deep the fstack will be, in 80-bit (\regc{TREAL}) wide cells, and then \bc{ALLOT} 10* that number of bytes of storage.
    \item We need a word that will initialize the 80x87 and fstack.
    \item We need a fast way to increment (or decrement) the address of the next availabe space in the fstack by 10.
    \item We need to test whether the 87stack is full (or empty).
    \item Finally, what do we do if the memory we set aside gets full? The solution chosen below makes the extension circular using modulo arithmetic to compute the addresses within it.
\end{itemize}

We now exhibit the fstack manager program in fig. 4-2 on page 83 below. By now the reader should be familiar enough with FORTH style to understand the program logic with only moderate commenting and explanation. Remember- the program reads from the bottom up!

The key words are \bc{FPUSH} and \bc{FPOP}- they do the work. Every word that changes the 87stack has to be redefined to include either \bc{FPUSH} or \bc{FPOP} as appropriate.

As the test results in Table 4-5 below make clear, the high-level stack extension is too slow. Some optimization is necessary.

Table 4-5 fstack manager timings
8086 machine @ 4.77 MHz
40,000 \regc{FPUSH}'s and \regc{FPOP}'s
\begin{center}
    \begin{tabular}{|c c c|}
        \textbf{High-level} & \textbf{Optimized} & \textbf{Hand-coded} \\
        29 sec              & 6 sec              & 4 sec \\
    \end{tabular}
\end{center}

HS/FORTH comes with a very helpful utility: a recursive-descent optimizer. The optimizer replaces the subroutine calls of ordinary high-level threaded FORTH code by in-line machine code.

\begin{listing}
\ FLOATING POINT STACK MANAGER
DECIMAL
VARIABLE FS-SIZE                ( size of fstack in TREAL's  ) 
40 FS-SIZE !                    ( the fstack is 40 deep      )
VARIABLE FLGTH                  ( length of fstack in bytes  )
VARIABLE FSP                    ( current offset into fstack )
VARIABLE FDEPTH                 ( current size of stack      )
                                ( -8 fdepth fs-length        )
CREATE FSTACK FS-SIZE @ 10 * ALLOT OKLW
: FSINIT FSP O! -8 FDEPTH ! FS-SIZE @ 10 *
      FLGTH ! FINIT ;           ( initialize 8087 and stacks )
CODE 10+      <% 83 C3 0A %>    END-CODE
CODE 10-      <% 83 eb 0A %>    END-CODE
       ( fast way to add or subtract 10 )
FSINIT

: WRAP ( fsp -- fsp mod flgth ) 
       [FLGTH @ ] LITERAL UNDER + SWAP MOD ;

: AWAY! DUP ROT ! ; ( adr n -— n ) \ useful factored word
: INC-FSP ( -- fsp') FSP DUP@ 10+ WRAP AWAY!  ;
: DEC-FSP ( -- fsp') FSP DUP@ 10— WRAP SWAP ! ;

: INC—FDEPTH                    ( -- fdepth' )
      FDEPTH DUP@ 1+ FS-LEGTH @ MIN
      AWAY! ;

: DEC-FDEPTH                    ( -- fdepth' )
      FDEPTH DUP@ 1- DUP -8 <
      ABORT" FSTACK UNDERFlOW" AWAY! ;

: FPUSH INC-FDETH O< NOT
      IF INC-FSP FSTACK +
          FDECSTP R80!          ( st[7] -- fsp )
      THEN ;

: FPOP DEC-FDEPTH -1 < NOT
       IF FSP @ FSTACK +
       R80@ FINCSTP             ( fsp -- st[7] )
       DEC-FSP THEN ;
\end{listing}
Fig. 4-2 Hi-level manager for 80x87

stripping out redundant pushes and pops of the parameter stack. It is fairly straightforward to construct a similar optimizer for any FORTH dialect. Alternatively, one can machine code the time-critical words.

The results of the tests, presented in Table 4-5 on page 82 above,
are interesting:
\begin{itemize}
    \item the optimizer does nearly as well as hand-tuned machine code.
    \item An \regc{FPUSH} or an \regc{FPOP} takes about 50 ysec on the average, when coded by hand, @ 4.77 MHz, or about 240 clock cycles.
    \item The irreducible minimum on an 8086/80286 -since \regc{TREAL} storage from, or retrieval to the 87stack' rs demanded— cannot possibly be less than 170 clock cycles: 1 fetch and 1 store\footnote{Somewhat less, \approx 100 clocks, if a 32-bit bus is utilized with the '386/'387 pair. See, \eg, John H. Crawford and Patrick F. Gelsinger, \textit{Programming the 80386} (Sybex, San Francisco, 1987).}. (The main place to save some time would be in moves to or from memory; the depth of the fstack and the pointer must be kept as variables, but \bc{FS-SIZE} and \bc{FLGTH} do not change and could be compiled as literals, thereby saving 30 cycles in \bc{FPUSH} and 10 in \bc{FPOP}.)
    \item Substantially greater efficiency (at best another 1.5x improvement over the code version discussed above) would require a different algorithm -based, perhaps, on the 87stack overflow or underflow interrupt. But because other error conditions can initiate this interrupt, the testing and decision-making needed to use this method seemed to me likely to produce equivalent overhead to the method employed here.

\section{Clone wars}

\TallC{S}{everal} companies have produced non-infringing clones of the Intel 80x87 family of chips. American Micro Devices is a second source for 80287 and 80387 chips. Cyrix Corporation has produced 80287 and 80387 equivalents with significantly faster transcendental functions and moderately faster arithmetic than , the Intel originals.

And finally, Integrated Information Technology, Inc. (founded by the designers of the Weitek chips) has produced the most interesting of the clones: the 80c287/80c387 not only perform arithmetic significantly faster than the Intel originals, they possess 24 additional 80-bit on-chip registers. Unfortunately these cannot be combined directly with the eight original registers to make a 32-deep stack, since this would have required increasing the 80x87 stack-pointer (see 7 above) from 3 bits to 5. Since there was no place to find the 2 extra bits, one cannot really fault IIT's designers.

But if they cannot be used to extend the 87stack, what are the 24
extra registers good for? Eight (bank 3) are not even accessible,
being used to speed up on-chip arithmetic. However, banlm 0-2
— 24 registers — can be accessed (cg. for on-chip cache memory).
Moreover, IIT has provided an on-chip linear transformation: a
4x4 matrix multiplies a 4-dimensional column vector in place. (The
original vector is overwritten, but the matrix is unchanged.) It worls
like this :

first we define the instructions

CODE FSBPO <96 DB E8 96> END-CODE
CODE FSBP1 <96 DB EB 96> END-CODE
CODE FSBP2 <96 DB EA 96> END-CODE
CODE F4x4 <96 DB F1 96 > END-CODE

Then we load the 4x4 matrix into banks 1 and 2, the vector into
bank 0, and multiply:

o VAR a{{ o VAR v{

: VEC- > 087 ( adr ~ - ) \ load vector into 80c387
IS V{ \ I vector address to V{
fiNIT FSBPO \ reset ST. select bank 0

30 DOV{I} G@ LOOP ;
: MAT->087 (adr--) \Ioad matrix into 80c387

IS a{{ \ ! matrix address to a{{
fiNIT FSBP2 \ reset ST, select bank 2
1 0 DO

30 DO a{{IJ}} G@ LOOP
P \cont'd

 

20. Note: fiNIT operates difierently on IIT’s coprocessors than on Intel’s. It does not place NAN‘s
in all 8 87stack cells.

30 DO v{l} GI LOOP;
\example: ANS = A*V
A{{ MAT->87 V{ VEC->87 F4x4 ANs{ce7->VEC

Chapter 4 — rite eoxa-r FamIIy Scientific FORTH 5‘
fiNIT FSBP1 \ reset ST, select bank 1
3 2 DO
SODOa{{IJ}}G@ LOOP
LOOP ; I
I
087- >VEC (adr - - ) \ I from 800387 to vector 1
IS V{ \ I vector address to v{ ‘
FSBPO \ select bank 0 %

 

\TallC{T}{he} on-chip 4x4 matrix multiply was intended to accelerate

3-dimensional graphics (rotation and translation can be ex-
pressed as a single 4-dimensional transformation). However, most
scientific programmers spend little time on 3-D graphics. The matrix
instructions are more interesting for their potential to accelerate
general matrix operations21. For example, suppose we need to -_
transform a vector by multiplying with an arbitrary matrix. Normally i
we would write ‘

   

II
Yi = 21 Aijxj (7) i
J:

But consider, e.g., an 8 x 8 matrix operating on an 8-dimensional i
column vector: we partition the matrix and vector into 4-dimen- g
sional sub-matrices an , etc. and sub-vectors x1 , etc.: '

_ an 012 X1 _ 01131 + 611212
[A] [x] _ [021 022] [‘2] [anti + 022352] (8)
From timings on assembly-coded demonstration programs that
multiply vectors by constant 4 x 4 matrices, we estimate an overall
speedup of 6—7 -fold on an 80c387 system. The timings for this
process are as shown in Table 4-6 below (assume 32-bit REAL'4
matrices). The execution time for a 4-dimensional linear trans-
formation using conventional operations is approximately 1744

clock cycles. The time using the vector operation is some 30-300
clocks, based on measured performance. Since 256 clocks are

 

21.

See Ch. 9 of this book for a fuller discussion of standard matrix algorithms.

MPORTH

awa-mmrrm O7

needed to load and store a 4-dimensional vector, we therefore
estimate the vector operation F4“ takes only about 50 clocks,
ale. about I floating point multiplication time. We can now es-
timate the time to multiply two 4 x 4 matrices as about 1200 cloclu
vs. about 7000 for the scalar process, Le. the same speedup factor

Table 46 Timings for 4x4 matrix - vector

Operation: x + @ I
mx mm: 16-52 12'28 20-20 4'44

W: 832 336 400 176

as for matrix 'vector. If one must load the 4x4 matrix each time,
the speedup factor is less: about 35-fold because of the 16 addi-
tional fetches.

The conventionally programmed 8x8 matrix-vector multiply
should also be some 3-5 times faster than the scalar operations,
Le. there is no obvious speed gain — except being able to employ
the built-in vector instruction F4x4 — from partitioning the 8x 8
system into 4X4 sub-units. However, Strassen22 has pointed out
that if one can evaluate matrix products recursively, partitioning
can substantially speed the most time—consuming matrix opera-
tions, multiplication and inversion. For example, it appears as
though the product of two partitioned matrices,

[A] [B] = [::::;:][::::Z::] [c]

[C] = [allbll+alzb21 allblz+alzb22]

azlbll+azzb21 azlblz+azzbzz

(9)

 

22. v. Strassen, Numer. Math. 13 (1969) 134. See also v. Put, SIAMReview 26 (1984) 393.

cJtsanVNouetaaz-Aiingmm.

Chaptar4-Thewxa7Famly Scleno‘flcFORTH

requires 8 matrix multiplications and 4 matrix additions to
evaluate. Strassen has shown that in fact the evaluation can be
performed with 7 matrix multiplications:

p1 = (all + an) (b11 + bu)

p2 = (an + an) bn

p3 = all (b12 — b2)

p, = (—a,, + an) (b,1 + bu) (10)
p5 = (all + an) b22

p5 = an (-bll + bu)

P 7 = (012 ‘ (122) (1721 + bzz)

and 18 matrix additions:

Cu =P1‘P5 +176 +P7
€12=P3+Ps
(11)
€21 =P2 +P6
€22 =P1—P2 +P3 +P4

‘ V‘s-‘-

‘l firm V' was...“

Equations 10 and 11 look at first blush half as efficient as 8 .

multiplications and 4 additions. But let us examine the time to
multiply two partitioned matrices, first by the straightforward
method and then by Strassen's: clearly,

where Mn is the multiplication time andAn the addition time, for
square matrices of order n.

Setting n = 2" that (note A,l a! 0(n2) ) we see the recursion,
Eq. 12, is satisfied by an expression of form

tun-ml.“ +ca 4“ (13)

M4-Tham7Fan-ily I.

where m and I are the elementary multiplication and addition
times. Substituting 13in 12 we find A =- 8 and c - — 1, i.e.,

Mn - mn’ — an2 (14)
Applying the same idea to Strassen’s method we obtain

10,, = 710,, + um2 (15)
or

Ian-mn’w—San’, (16)
where

lg? E I092? = 2.807...

That is, partitioning allows a potentially large reduction in the
time to multiply dense matrices.

\TallC{B}{y} writing a partitioned matrix in the form

an at: | 0 all 812 ..
= = 1
[A] [82‘ 82;] [52131—11 ' i 0 z i ( I)

where

 

z = 322 — anal—9a.. (18)

I 0
[—azrar-t1 '] (19)

we may express the inverse of A as

which leads to the recursion for In , the time to invert an nxn
matrix:
\begin{align}
l_{2n} \cong 2l_{n} + 5M_{n}
\end{align} 

whose solution is
\begin{align}
l_{n} = mn^{lg 7} + O(n)
\end{align}

\textit{i.e.}, the time needed to invert is comparable with that needed to multiply.

\TallC{S}{uppose} we merely wish to solve a linear system without inverting the matrix: can we gain some speed that way? From 17 we
see that the problem

\begin{align*}
Ax=y
\end{align*}

reduces to three sub-problems:

\begin{align}
    a_{11}u_{1} = y_{1}                 \\
    zx_{2} = y_{2} - a_{21}{u}_1        \\
    a_{11}x_{1} = y_{1} - a_{12}x_{2}
\end{align}

that is, we have the recursion

\begin{align}
S_{2n} = 3S_{n} + mn^{lg 7} + 2mn^{2}
\end{align}

whose solution is dominated by
\begin{align}
S_{n} = m\left(\frac{1}{4}n^{lg 7} + 2n^{2}\right) + O(n^{lg 3})
\end{align}

Linear equation solution via recursion thus has the same asymptotic running time as matrix multiplication, except that 4 x fewer operations are required than for inversion. That is, it should be about 5 x faster to solve a dense system of 1000 linear equations by recursive partitioning than by ordinary Gaussian elimination even on a scalar processor. The vector instruction on the ITT 80c387 chip, together with Strassen's algorithm, offers the possibility of solving very large systems in practical times, on desktop computers.