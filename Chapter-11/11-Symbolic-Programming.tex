% Chapter 11 -- Symbolic Programming

\chapter{Symbolic Programming}
\TallC{All} symbolic programming is based on \textbf{rules} --- a set of generalized instructions that tells the computer how to transform one set of \textbf{tokens} into another. An assembler, \textit{e.g.}, inputs a series of machine instructions in mnemonic form and outputs a series of numbers that represent the actual machine instructions in executable form. A FORTH compiler translates a definition into a series of addresses of previously defined objects. Even higher on the scale of complexity, a FORTRAN compiler inputs high-level language constructs formed according to a certain \textbf{grammar} and outputs an executable program in another language such as assembler, machine code or C.

What do rules have to do with scientific problem-solving? The crucial element in the rule-based style of programming is the ability to specify general \textbf{patterns} or even classes of patterns so the computer can recognize them in the input and take appropriate action.

For example, in a modern high-energy physics experiment the rate at which events (data) impinge on detectors might be $10^{7}$ discrete events per second. Since each event might be represented by 5-10 numbers, the storage requirements for recording the results of a search for some rare process, lasting 3-6 months of running time, might be $10^16$ bytes, or $10^7$ high-capacity disk drives! Clearly, so much storage is out of the question and most of the incoming data must be discarded. That is, such experiments demand extremely fast filtering methods that can determine - in 10-20$\mu$sec - whether a given event is interesting. The criteria for "interesting" may be quite general and may need to be changed during the running of the experiment. In a word, they must be specified by some form of pattern recognition program rather than hard-wired.

Another area where pattern recognition helps the scientist is computer algebra. Closely related is the ability to translate mathematical formulae into machine code. So far we have stressed a FORTH programming style natural to that language, namely postfix notation, augmenting it primarily for readability or abstracting power. It cannot be denied, however, that sometimes it is useful simply to be able to write down a mathematical formula and have it translated automatically into executable form. This chapter develops the tools for symbolic programming and illustrates their use with a typical algebra program and a simple FORmula TRANslator.

\section{Rules}
Before we can specify rules we need a language to express them in. We need to be able to describe the \textbf{grammar} of the rules in some way. The standard notation states rules as \textbf{regular expressions\sepfootnote{11_01}}. The following rules describing some parts of FORTRAN illustrate how this works.

\begin{verbatim}
\ Rules for FORTRAN

\ NOTATION:
\ |         -> "or"
\ ^         -> "unlimited repetitions"
\ ^n        -> "0-n repetitions"
\ Q         -> "empty set"
\ &         -> + | -
\ %         -> * | /
\ <d>       -> "digit"

\ NUMBERS:
\ <int>     -> {-|Q} {<d> <d> ^8}
\ <exp't>   -> {dDeE} {&|Q}{<d> <d> ^2} | Q
\ <fp\#>    -> {-|Q}{ <d> | Q} . <d> ^ <exp't>

\ FORMULAS:
\ <assign>  -> <subj> = <expression>
\ <id>      -> <letter> {<letter>|<d>}^6
\ <subject> -> <id> {<idlist> | Q}
\ <idlist>  -> ( <id> {, <id> } ^)
\ <arglist> -> ( <expr'n> {, <expr'n>}^)
\ <func>    -> <id> <arglist>
\ <expr'n>  -> <terrn> | <terrn> & <expr'n>
\ <terrn>   -> <fctr> | <fctr> % <trm> | <fctr>**<fctr>
\ <factor>  -> <id> | <tp#> |(<expr'n> )| (tum)

\end{verbatim}

We use angular brackets "<", ">" to set off "parts of speech" being defined, and arrows "->" to denote "is defined by". Other notational conventions, such as "|" to stand for "or", are listed in the "NOTATION" section of the rules list, mainly for mnemonic reasons. A statement such as

\begin{verbatim}
\ <int>     -> {-|Q}<d><d>^8
\end{verbatim}

therefore means "an integer is defined by an optional leading minus sign, followed by 1 digit which is in turn followed by as many as 8 more digits". Similarly, the phrase

\begin{verbatim}
\ <assign>  -> <subj> = <expression>
\end{verbatim}

means “an assignment statement consists of a subject --a symbol that can be translated into an address in memory-- followed by an equals sign, followed by an expression". Literal symbols -- parentheses, decimal points, commas-- are shown in \textbf{bold} type.

Note that some of these definitions are \textbf{recursive}. A statement such as

\begin{verbatim}
\ <expr'n>  -> <term> | <term> & <expr'n>
\end{verbatim}

seems to be defined in terms of itself. So it is a good bet the program that recognizes and translates a FORTRAN expression will be recursive, even if not explicitly so.

\section{Tools}
\TallC{In} order to apply a rule stated as a regular expression, we need to be able to recognize a given pattern. That is, given a string, we need -say- to be able to state whether it is a foating point number or something else. We want to step through the string, one character at a time, following the rule

\begin{verbatim}
\ <fp#>     -> {-|Q}{{d . | .d | d} d ^ exp't
\end{verbatim}

This pattern begins with a minus or nothing, followed by a digit and a decimal point or a decimal point and a digit or a digit with no decimal point, followed by zero or more digits, then an exponent.

\subsection{Pattern recognizers}
\TallC{One} often sees pattern recognizers expressed as complex logic trees, \textit{i.e.} as sequences of nested conditionals, as in Fig. \ref{fig:11_01} on page \pageref{fig:11_01} below. As we see, the tree is already five levels deep, even though we have concealed the decisions pertaining to the exponent part of the number in a word \textbf{exponent?}. When programmed in the standard procedural fashion with \bc{IF...ELSE...THEN} statements, the program becomes too long

\begin{figure}
    \caption{Fig. 11-1 \textit{Logic tree for <floating point \#>}}
    \label{fig:11_01}
\end{figure}

and too complex either for easy comprehension or for easy maintainance\sepfootnote{11_02}.

It has been known for many years that a better way to apply general rules - \textit{e.g.}, to detemiine whether a given string conforms to the rules for "foating point number" --- uses \textbf{finite state machines} (FSMs -we define them in \ref{chap:11_02_02} below). Here is an example, written in standard FORTH:

\begin{lstlisting}
    \ determine whether the string at Sadr is a fp#
    :skip-   ( adr -- adr' ) DUP C@ ASCII- = - ;
    :skip_dp ( adr -- adr' ) DUP C@ ASCII. = - ;
    \ NOTE: these "hacks" assume "true" = -1.
    :digit?  ( char -- f ) ASCII 9 ASCII 0 WITHIN ;
    : skip_dig ( adr2 adr1 -- adr2 adr1')
        BEGIN   DDUP > OVER C@ digit? AND
        WHILE     1+  REPEAT ;   \... cont'd below
    :dDeE?   ( char -- f) 95 AND \->uppercase
        DUP ASCII D = SWAP ASCII E = OR ;

    : skip_exponent ... ; \ this definition shown below

    :fp#?    ( $adr -- f )
        DUP 0 OVER COUNT + C! \ add terminator
        DUP C@ 1+ OVER C!     \ count = count+1
        COUNT OVER + 1- SWAP  ( -- $end $beg )
        skip- skip_dig skip_dp skip_dig
        skip_exponent
        UNDER =          \ $beg' = $end?
        SWAP C@ 0= AND ; \ char[$beg']=terminal?
\end{lstlisting}

The program works like this:

\begin{itemize}
    \item Append a unique terminal character to the string.
    \item If the first character is "-" advance the pointer 1 byte, otherwise advance 0 bytes.
    \item Skip over any digits until a non-digit is found.
    \item If that character is a decimal point skip over it.
    \item Skip any digits following the decimal point.
    \item A foating point number terminates with an exponent formed according to the appropriate rule (p. 261). \bc{skip_exponent} advances the pointer through this (sub)string, or else halts at the first character that fails to fit the rule.
    \item Does the initial pointer (\$beg') now point to the calculated end of the string (\$end)? And is the last character ( char[\$beg'] ) the unique terminal? If so, report "true", else report "false".
\end{itemize}

We deferred the definition of \bc{skip_exponent}. Using conditionals it could look like

\begin{lstlisting}
    : skip_exponent ( adr -- adr' )
        DUP C@ dDeE?    IF 1+ ELSE EXIT THEN
        skip- skip+
        DUP C@ digit?   IF 1+ ELSE EXIT THEN
        DUP C@ digit?   IF 1+ ELSE EXIT THEN
        DUP C@ digit?   IF 1+ ELSE EXIT THEN ;
\end{lstlisting}

which,as we see in Fig. \ref{fig:11_02} below, has nearly as convoluted a logic tree as Fig. \ref{fig:11_01} on page \pageref{fig:11_01} above.

\subsection{finite state machines}\label{chap:11_02_02}

Just as we needed a FSM to achieve a graceful definition of \bc{fp\#?}, we might try to define \bc{skip_exponent} as a state machine also. This means it is time to define what we mean by finite state machines. (We restrict attention to \textbf{deterministic} FSMs.) A \textbf{finite state machine\sepfootnote{11_03}\sepfootnote{11_04}} is a program (originally it was a hard-wired switching circuit\sepfootnote{11_05}) that takes a set of discrete, mutually exclusive

\begin{figure}
    \caption{Fig. 11-2 \textit{Logic tree for <exponent>}}
    \label{fig:11_02}
\end{figure}

inputs and also maintains a \textbf{state variable} that tracks the history of the machine's inputs. According to which state the machine is in, a given input will produce different results. The FSM program is most easily expressed in tabular form, as in Table \ref{table:11_01}, which we interpret as follows:

\begin{itemize}
    \item each major column heading is an input.
    \item the inputs must be \textbf{mutually exclusive} and \textbf{exhaustive}; to exhaust all possibilities we include "other".
    \item each row represents the current state of the machine.
    \item each cell contains an action, followed by a state-transition.
\end{itemize}


\begin{table}[h!]
    \caption{Example of finite state machine arrow ( $\rightarrow$ ) means 'next state'}
    \begin{center}
        \begin{tabular}{|lllllllll|}
            \hline
\underline{Input:} & \underline{other} & & \underline{dDeE} & & \underline{+/-} & & \underline{digit} &    \\
        State      &     & $\rightarrow$ &    & $\rightarrow$ &   & $\rightarrow$ &        & $\rightarrow$ \\
      $\downarrow$ &                   & &                  & &                 & &                   &    \\
            0      & \lgray{Next}  & 5  & 1+           & 1  & \Aggray{Error}& 5   & \lgray{Next}  & 5      \\ &&&&&&&& \\
            1      & \lgray{Next}  & 5  & \lgray{Next} & 5  & 1+            & 2   & 1+    & 3              \\ &&&&&&&& \\
            2      & \lgray{Next}  & 5  & \lgray{Next} & 5  & \lgray{Next}  & 5   & 1+    & 3              \\ &&&&&&&& \\
            3      & \lgray{Next}  & 5  & \lgray{Next} & 5  & \lgray{Next}  & 5   & 1+    & 4              \\ &&&&&&&& \\
            4      & \lgray{Next}  & 5  & \lgray{Next} & 5  & \lgray{Next}  & 5   & 1+    & 5              \\ &&&&&&&& \\
            \hline
        \end{tabular}
    \end{center}
    \label{table:11_01}
\end{table}

\TallC{The} tabular representation of a FSM is much clearer than the logic diagram, Fig. \ref{fig:11_02}. Since the inputs must be \textbf{mutually exclusive}\sepfootnote{11_06} and \textbf{exhaustive}\sepfootnote{11_07}, there are \textit{never} conditions that cannot be fulfilled -that is, leading to "dead" code- as frequently happens with logic trees (owing to human frailty). This means the chance of introducing bugs is reduced by FSMs in tabular form.

FORTRAN, BASIC or Assembler can implement FSMs with computed GOTOs. In BASIC, \eg,

\begin{verbatim}
    DEF SUB FSM (c$, adress%)
    k% =0         ' convert input to column #
    C$=UCASE (c$)
    IF C$="D" OR C$="E" THEN k%=1
    IF C$="+" OR C$="-" THEN k%=2
    IF ASC(C$) >= 48 AND ASC(C$) <=57 THEN k%=3
    ' cont'd
\end{verbatim}


\begin{tabular}{ll}
\verb!      ' begin FSM proper!                                  & \\
\verb!    ON state\% *3 + k\% GOTO!                              & \\
\verb!      (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19)! & \\
\verb!    0: state\%=5!               & \rdelim\}{4}{*}[' row 1]   \\
\verb!    1: adress\% = adress\% +1 : state\% = 1!               & \\
\verb!    2: CALL Error: state\% = 5!                            & \\
\verb!    3: state\%=5!                                          & \\
\verb!    4: state\%=5!               & \rdelim\}{4}{*}[' row 2]   \\
\verb!    5: state\%=5!                                          & \\
\verb!    6: adress\% = adress\% +1 : state\% = 2!               & \\
\verb!    7: adress\% = adress\% +1 : state\% = 3!               & \\
\verb!       ...... etc. ......!                                 & \\
\verb!    16:state\%=5!               & \rdelim\}{3}{*}[' row 4]   \\
\verb!    ...... etc.......!                                     & \\
\verb!    19:adress\% = adress\% +1 : state\% = 5!               & \\
\verb!    END SUB!                                               & 
\end{tabular}


The advantage of FSM construction using computed GOTOs is simplicity; its disadvantage is the linear format of the program that hides the structure represented by the state table, 11-1. CASE statements -as in C, Pascal or QuickBASIC- are no clearer. We can use a state table for documentation, but the subroutine takes more-or-less the above form.

\subsection{FSMs In FORTH}
\TallC{In} the preceding FORTH example we \textit{synthesized} the FSM from \bc{BEGIN} \bc{...} \bc{WHILE} \bc{...} \bc{REPEAT} loops. FORTH's lack of line-labels and GOTOs (jumps) imposed this method, producing code as untransparent as the BASIC version. The Eaker CASE statement can streamline the program,

\begin{lstlisting}
    CASE: ADVANCE? NEXT 1+ ;CASE
    : 1digit DUP C@ digit? ABS ADVANCE? ;
    : skip_exponent (adr -- adr')
        DUP C@ dDeE? IF 1+ ELSE EXIT THEN
        skip- skip+
        1digit 1digit 1digit ;
\end{lstlisting}

(three of four \bc{IF...ELSE...THEN}s have been factored out and disguised as \bc{CASE:} \bc{...} \bc{;CASE} ), but this does not much improve clarity. We still need the state transition table to understand the program.

Various authors have tried to improve FSMs in FORTH using what amount to line-labels and GOTOs\sepfootnote{11_08}\sepfootnote{11_09}\sepfootnote{11_10}. The resulting code is \textit{less} elegant than the BASIC version shown above.

\TallC{Whenever} we reach a dead end, it is helpful to return to the starting point, restate the problem and re-examine our basic assumptions One fact our preceding false starts make abundantly clear is that nowhere have we used the power of FORTH. Rather, our attempts merely imitated traditional languages in FORTH.

But FORTH is an endlessly protean language that lends itself to \textit{any} programming style. Ideally FORTH relies on names so cunningly chosen that programs become self-documenting-- readable at a glance.

Since state tables clearly document FSMs, it eventually occurred to me to let FORTH compile the state table --representing an FSM-- directly to that FSM!

\TallC{Compilation}implies a \textbf{compiling word}; after some experimentation\sepfootnote{11_11} I settled on the following usage\sepfootnote{11_12}:

\begin{figure}[H]
    \begin{tabular}{|c|}
        \hline
        \begin{lstlisting}
    4 WIDE   FSM:   (exporters)
    \ Input: | other    | dDeE      | +/-       | digit  |
    \ state: - - - - - - - - - - - - - - - - - - - - - - -
     (0)     NEXT   >5    1+   >1   Error  >5   NEXT   >5
     (1)     NEXT   >5  NEXT   >5     1+   >2     1+   >3
     (2)     NEXT   >5  NEXT   >5   NEXT   >5     1+   >3
     (3)     NEXT   >5  NEXT   >5   NEXT   >5     1+   >4
     (4)     NEXT   >5  NEXT   >5   NEXT   >5     1+   >5 ;
        \end{lstlisting} \\
        \hline
    \end{tabular}
    \caption{Fig. 11-3 \textit{Form of a FORTH finite state machine}}
    \label{fig:11_03}
\end{figure}

The new defining word \bc{FSM:} has a colon ":" in its name remind us of its function. Its children clearly must "know" how many columns they have. The word \bc{WIDE} reminds us the newly created FSMs incorporate their own widths.

The column labels and table headers are merely commenst for following the state labels "$\textbackslash$" ; the state labels " \bc{( 0 )} ", " \bc{( 1 )} ", \etc are also comments, delineated with parentheses. Their only purpose is readability.

The actions -- \bc{NEXT, Error, 1+} -- in Fig. \ref{fig:11_03} are obvious: they; are simply previously-defined words. But what about the state: transitions " \bc{>1} ", " \bc{>2} ", ... ? The easiest, most mnemonic and natural way to handle state transitions defines them as \bc{CONSTANT}s

\begin{lstlisting}
    0 CONSTANT >0
    1 CONSTANT >1
    2 CONSTANT >2
      ... etc. ...
\end{lstlisting}

which are also actions to be compiled into the FSM. This follows the general FORTH principle that words should execute themselves\sepfootnote{11_13}.

\TallC{In} Chapter \ref{chap:05_02_06} we used components of the compiler, particularly the \bc{IMMEDIATE} word \bc{]} ("switch to compile mode"), to create self-acting jump tables. We apply the same method here: The defining word \bc{FSM:} will \bc{CREATE} a new dictionary entry, build in its width (number of columns) using " \bc{,} ", and then compile in the actions and state transitions as cfa’s of the appropriate words.

The runtime code installed by \bc{DOES>} provides a mechanism for finding the addresses of action and state transition corresponding to the appropriate input and current \textbf{state} (that is, in the cell of interest). Then the runtime code updates the \textbf{state}.

To allow* nesting of FSMs (\ie, compiling one into another), we incorporate the state variable for each child FSM within its data structure. This technique, using one extra memory cell per FSM, protects the \textbf{state} from accidental interactions, since if \textbf{state} has no name it cannot be invoked inadvertamly.

The FORTH code that does all this is
\begin{lstlisting}
    : WIDE 0 ;
    : FSM:      ( width 0 -- ) CREATE , , ]
        DOES>   ( col# -- )
            UNDER D@        ( -- adr col# width state )
            * + 1+ 4*       ( -- adr offset )
            OVER+           ( -- adr adr' )
            DUP@ SWAP 2+    ( -- adr [adr'] adr'+2 )
            ROT ! @EXECUTE   ;

    0 CONSTANT >0
    1 CONSTANT >1
    2 CONSTANT >2
    ... etc. ...
\end{lstlisting}

\TallC{We} are now in a position to use the code for \bc{(exponent)} (defined in Fig. \ref{fig:11_03} on page \pageref{fig:11_03} above) to define the key word \bc{skip_exponent} appearing in \bc{fp\#?}. The result is

\begin{lstlisting}
    : skip_exponent     ( adr -- adr' )
    ' (exponent) 0!     \ initialize state
    BEGIN   DUP C@ DUP  (  -- adr char )
        dDeE? ABS OVER  \ input -> col#
        +/-?    2 AND + SWAP
        digit?  3 AND + ( -- adr col# )
    ' (exponent) @      \ get state
    5 <                 \ not done?
    WHILE (exponent) REPEAT ;
\end{lstlisting}

\subsection{Automatic conversion tables}
\TallC{Our} preceding example used logic to \textbf{compute} (\textit{not} decide!) the conversion of input condition to a column number, \textit{via}

\begin{lstlisting}
    ( -- char) dDeE?  ABS OVER
               +/-?   2 AND + SWAP
               digit? 3 AND + ( -- col#)
\end{lstlisting}

When the input condition is a character, it is usually both faster and clearer to translate to a column number using a lookup table rather than tests and logic. That is, we can trade increased memory usage for speed. If a program needs many different pattern recognizers, it is worth generating their lookup tables via a defining word rather than crafting each by hand.

\begin{lstlisting}
    : TABLE:            ( -- #bytes )
        CREATE HERE     ( -- #bytes tab[0] )
        OVER ALLOT      \ allot #bytes in dictionary
        SWAP 0 FILL     \ initialize to all 0's
        DOES> + C@ ;   ( n tab[0] -- [tab[n]] )

    : install ( col# adr char.n char.1 -- ) \ fast fill
        SWAP 1+ SWAP
        DO DDUP I+ C! LOOP DDROP ;
\end{lstlisting}

Here is how we define a new lookup table:

\begin{lstlisting}
    128 TABLE: [exp]        \ define 128-byte table
    \ modify certain chars
    \ Note: all unmodified chars return col# 0

    1 ASCII d '[exp] + C!            \ col# 1
    1 ASCII D '[exp] + C!
    1 ASCII e '[exp] + C!
    1 ASCII E '[exp] + C!
    
    2 ASCII + '[exp] + C!            \ col# 2
    2 ASCII - '[exp] + C!

    3 '[exp] ASCII 9 ASCII 0 install \ col# 3
\end{lstlisting}

With the lookup table \bc{[exp]}, \bc{skip_exponent} becomes faster and more graceful,

\begin{lstlisting}
    : skip_exponent ( adr -- adr' )
        1 (exponent) 0!             \ state = 0
        BEGIN DUP C@                ( -- adr char )
            [exp]                   ( -- adr col# )
            ' (exponent) @          ( -- adr col# state )
            5 <                     \ not done?
        WHILE (exponent) REPEAT     ;
\end{lstlisting}

at a cost of 128 bytes of dictionary space. If dictionary space becomes tight, it would be perfeme simple to export the lookup tables to their own segment. in the same way we did with generic arrays in Chapter \ref{chap:05}.

\section{Computer algebra}
\TallC{One} of the most revolutionary recent developments in scientific  programming is the ability to do algebra on the computer. Programs like REDUCE, SCHOONSCIP, MACSYMA, DERIVE, and MATHEMATICA can automate tedious algebraic manipulations that might take hours or years by hand, in the process reducing the likelihood of error\sepfootnote{11_14}. The study of symbolic manipulation has led to rich new areas of pure mathematics\sepfootnote{11_15}. Here we illustrate our new tool (for compiling finite state automata) with a rule-based recursive program to solve a problem that does not need much formal mathematical background. The resulting program executes far more rapidly on a PC than REDUCE, \eg, on a large mainframe.

\subsection{Stating the problem}
\TallC{Dirac} $\gamma$-matrices are $4 \times 4$ traceless, complex matrices defined by a set of (anti)commutation relations\sepfootnote{11_16}. These are

\begin{equation} \label{eq:11_01}
\gamma^{\mu}\gamma^{v} + \gamma^{v}\gamma^{\mu} = 2 \eta^{\mu v}, \mu, v = 0,..., 3
\end{equation}

where $\eta^{\mu v}$ is a matrix-valued tensor,

\begin{equation}\label{eq:11_02}
    \eta^{\mu v} =
    \bordermatrix{
        \mu \textbackslash v & 0 &  1 &  2 &  3 \cr
        0 & I &  0 &  0 &  0 \cr
        1 & 0 & -I &  0 &  0 \cr
        2 & 0 &  0 & -I &  0 \cr
        3 & 0 &  0 &  0 & -I \cr
        }
\end{equation}

The \textbf{trace} of a matrix is defined to be the sum of its diagonal elements,

\begin{equation}\label{eq:11_03}
 Tr(\tr{A})\hat{=}\sum_{k=1}^{N}\tr{A}_{kk} .
\end{equation}

Clearly, traces obey the \textbf{distributive law}


\begin{subequations}\label{eq:11_04}
    \begin{equation}\label{eq:11_04_a}
        Tr(\tr{A} + \tr{B}) \equiv \Tr{A} + \Tr{B}
    \end{equation}
        as well as a kind of \textbf{commutative law},
    \begin{equation}\label{eq:11_04_b}
        Tr(\tr{A} \tr{B}) \equiv Tr(\tr{B} \tr{A}).
    \end{equation}
\end{subequations}

From Eq. \eqref{eq:11_01}, \eqref{eq:11_02}, and \eqref{eq:11_04_a},b we find

\begin{align}\label{eq:11_05}
    & Tr(\tr{A} \tr{B}) \equiv \frac{1}{2} \left[ Tr(\tr{A} \tr{B}) + Tr(\tr{B} \tr{A}) \right] = \frac{1}{2} Tr(\tr{A} \tr{B} + \tr{B} \tr{A}) \nonumber \\
    & = \frac{1}{2} 2 A \cdot B \Tr{I} \equiv 4 A \cdot B
\end{align}

where the ordinary vectors $A^{\mu}$ and $B^{v}$ form the (Lorentz-in-variant) "dot product"

\begin{equation}\label{eq:11_06}
A \cdot B \equiv A^{0} \cdot B^{0} - A^{1} \cdot B^{1} - A^{2} \cdot B^{2} - A^{3} \cdot B^{3}
\end{equation}

The trace of 4 gamma matrices can be obtained, analogous to Eq. \eqref{eq:11_05}, by repeated application of the algebraic laws 1-4:

\begin{align}\label{eq:11_07}
Tr(\tr{A}\tr{B}\tr{C}\tr{D}) & = 2A\cdot B Tr(\tr{C}\tr{D}) - Tr(\tr{B}\tr{A}\tr{C}\tr{D}) \nonumber \\
& \equiv 2 A\cdot B Tr(\tr{C}\tr{D}) - Tr(\tr{A}\tr{B}\tr{C}\tr{D}) \\
& \equiv 4 \left(A\cdot B C \cdot D - A\cdot C B\cdot D + A\cdot D B \cdot C \right) \nonumber 
\end{align}

We include Eq. \eqref{eq:11_07} for testing purposes. The factors of 4 in Eq. \eqref{eq:11_05} and \eqref{eq:11_07} do nothing useful, so we might as well suppress them in the, interest of a simpler program.

\subsection{The rules}
\TallC{We} apply formal rules analogous to those used in parsing a language\sepfootnote{11_17}. The rules for traces are:

\begin{verbatim}
\ Gemma Matrix Algebra Rules:

\ a              ->     string of booth <= 3
\ /              ->     delineator for factors
\ <factor>       ->     a/
\ product/       ->     e/b/c/d/
\ Tr( a/b/prod/) ->     a.b ( tr( prod/) ) - tr( a/prod/b'/ )
\ b'             ->     mark b as permuted
\ Tr( a/)        ->     0 ( a single factor is traceless)
\end{verbatim}

Repeated (adjacent) factors can be combined to produce a multiplicative constant:

\begin{align}\label{eq:11_08}
    \tr{B}\tr{B} \equiv B \cdot B ;
\end{align}

recognizing such factors can shorten the final expressions significantly, hence the rule

\begin{verbatim}
\ Tr( a/a/prod/) ->     a.a ( Tr( prod/) ).
\end{verbatim}

In the same category, when two vectors are orthogonal, $A\cdot B = 0$, another simplification occurs,

\begin{verbatim}
\ PERP A B       ->     A.B = 0.
\ Tr(A/B/prod/)  ->     -Tr( A/prod/B'/)
\end{verbatim}

The ability to recognize orthogonal vectors lets us (correctly)
include the trace of a product times the special matrix\sepfootnote{11_18}

\begin{equation}\label{eq:11_09}
    \gamma^{5} = i \gamma^{0} \gamma^{2} \gamma^{3} \gamma^{4} =
    \begin{pmatrix}
        0 &  0 &  1 &  0 \\
        0 &  0 &  0 &  1 \\
        1 &  0 &  0 &  0 \\
        0 &  1 &  0 &  0 
    \end{pmatrix}
\end{equation}

that anticommutes with all four of the $\gamma^{\mu}$:

\begin{equation}\label{eq:11_09}
    \gamma^{5}\gamma^{\mu} + \gamma^{\mu}\gamma^{5} = 0, \mu = 0,...,3 . \nonumber
\end{equation}

The fully antisymmetric tensor $\varepsilon_{v\mu\kappa\lambda} -\varepsilon_{v\mu\kappa\lambda}$, \etc, lets* us write

\begin{equation}\label{eq:11_10}
\gamma^{5}\tr{A}\tr{B}\tr{C} \equiv i \varepsilon_{v\mu\kappa\lambda} A^{\mu}B^{v}C^{\kappa}\gamma^{\lambda}, i = \sqrt{-1}  .
\end{equation}

A complete gamma matrix package includes rules for traces containing $\gamma^{5}$:

\begin{verbatim}
\ Trg5( a/b/c/d/x/) ->  i Tr( ^/d/x/)
\ ^.d               ->  [a,b,c,d] (antisymmetric product)
\ Note: ^.a = ^.b= ^.c = 0
\end{verbatim}

Since $\gamma$-matrices often appear in expressions like $(\tr{A} + m_{A}I)$, it will also be convenient to include the additional rules

\begin{Verbatim}[commandchars=\\\{\}]
\ *A/            ->     [A/ + m\textsubscript{A}]
\ Tr(*A/X/)      ->     m[A](Tr(x/) ) + Tr(x/ A/)
\end{Verbatim}

\subsection{The program}
\TallC{We} program from the bottom up, testing, adding, and modifying as we go. Begin with the user interface; we would like to say

\begin{lstlisting}
    TR( A/B/C/D/)
\end{lstlisting}

to obtain the output:

\begin{lstlisting}
    = A.BC.D-A.CB.D + A.DB.C ok
\end{lstlisting}

Evidently our program will input a string terminated by a right parenthesis "\bc{)}", \ie, the right parsnthesis tells it to stop inputting This can be done with the word\sepfootnote{11_19}

\begin{lstlisting}
    : get$ ASCII) TEXT PAD X$ $! ;
\end{lstlisting}

Since the rules are inherently recursive, we push the input string onto a \textbf{stack} before operations commence. What stack? Clearly we need a stack that can hold strings of "arbitrary" length. The strings cannot be \textit{too} long because the number of terms of output, hence the operating time, grows with the number of factors N, in fact, like $\left(\frac{1}{2}N)\right)$\bc{!}.

The pseudocode for the last word of the definition is clearly something like

\begin{lstlisting}
    : TR(   )get$   \ get a $ -terminated with ")"
            setup   \ push  $ on $stack
            parse ;
\end{lstlisting}

The real work is done by \bc{parse}, whose pseudocode is shown below in Fig. \ref{fig:11_04}; note how recursion simplifies the problem of matching left and right parentheses in the output.

Next we define the underlying data structures. Recursion demands a \textbf{stack} to hold strings in various stages of decomposition and permutation. Since the number of terms grows very rapidly with the number of factors, it will turn out that taking the trace of as many as 20 distinct factors is a matter of some weeks on -say- a 25 Mhz 80386 PC; that is, 14 or 16 factors are the largest practicable number. So if we make provision for expressions 20 factors long, that should be large enough for practical purposes\sepfootnote{11_20}.

\begin{figure}
    \caption{Fig. 11-4 \textit{Pseudocode/flow diagram for "parse"}}
    \label{fig:11_04}
\end{figure}

How deep an the \$stack get? The algorithm expressed by the rule

\begin{verbatim}
\ Tr( a/b/prod/) -> a.b ( Tr( prod/) ) - Tr( a/prod/b'/)
\end{verbatim}

suggests that for an expression of length n=2k, the maximum depth will be k + 1. Thus we should plan for a stack depth of at least 11, perhaps 12 for safety. Assuming factor-names up to three characters long, and strings of up to 20 names, we need $\approx$60 characters per string. My first impulse was to create a dynamic \textbf{\$stack} that could accomodate strings of variable length, meaning that some 330 bytes of storage would be needed, at the cost of some complexity in keeping track of the addresses. This is a big improvement on 720 bytes needed for a 60-wide fixed-width stack, of course. However, the convenience of a fixed-width \$stack led me ultimately to set up a table (array) of 20 names, whose indices would act as tokens; that is, the strings that actually go on the \$stack would be tokenized. The memory cost of the table together with a 12-deep, fixed-width \$stack is thus only 80 + 242 = 322 bytes.

Since the tokens are 1-byte integers smaller than 32, their 5th, 6th, and 7th bits can serve as flags to indicate their properties. For example, we need to indicate whether a factor was "starred", \ie. whether it represents $(\tr{A} + m_{A}I)$ or $\tr{A}$ , according to the rule

\begin{verbatim}
\ *A/            ->     (A/ + m[A)).
\end{verbatim}

Again, we need to be able to indicate a "prime", showing that a factor has been permuted following the rule

\begin{verbatim}
\ Tr( a/b/prod/) ->     a.b ( tr( prod/) ) - tr( a/prod/b'/)
\end{verbatim}

Thus we set bit 7 (\bc{128 OR}) to indicate "star", and bit 6 (\bc{64 OR}) to indicate "prime".

We still need to indicate the leading sign. My first impulse was to use bit 5, but I realized the first factor is never permuted, hence, its 6th bit is available to signify the sign. It is toggled by the phrase \bc{64 XOR}. (In the \$stack pictures appearing in the Figures we indicate toggling by a leading "\bc{\~}".)

Programming these aspects is fairly trivial so we need not dwell on it. The entire program appears on pages 279 and 280 above.

Now we test the program:

\begin{lstlisting}
    TR( A/B/C/D/E/F/) =
    A.B(C.D(E.F)-C.E(D.F) + C.F(D.E))
   -A.C(D.E(B.F)-D.F(B.E) + B.D(E.F))
   +A.D(E.F(B.C)-B.E(C.F) + C.E(B.F))
   -A.E(B.F(C.D)-C.F(B.D) + D.F(B.C))
   +A.F(B.C(D.E)-B.D(C.E) + B.E(C.D)) ok
\end{lstlisting}

\TallC{Clearly} the concept works. Our next task is to incorporate branches to take care of "starred", as well as identical and/or orthogonal adjacent factors. The possible responses to the different cases are presented in decision-table form in Table \ref{table:11_02}:

To avoid excessively convoluted logic we eschew nested branching constructs. A finite state machine would be ideal for clarity; however, as Table \ref{table:11_02} makes clear, the logic is not really that of a FSM, besides which, the FSM compiler described above would

\begin{verbatim}

Input:    & a/b/x/   & *a/b/x/ & a/*b/x/ & a/a/x/ & a/b/x/,a.b=0

Resulting & ~a/x/b'/ & a/b/x/  & a/b/x/  & ...    & ...

$stack: XI b/XI a/x/ x/ "' a/x/b’l

Action(s): & a.b       & m[a]      & m[b]      & a.a       & RECURSE

           & (RECURSE) & (RECURSE) & (RECURSE) & (RECURSE) &

           & RECURSE   & RECURSE   & RECURSE

Note: characters shown in light typeface are \bc{EMIT}ed.
\end{verbatim}

have to be modified to keep its state variable on the stack, since otherwise it could not support recursion. The resulting pseudocode program is shown in Fig. \ref{fig:11_05}. Implementing the code is now straightforward, so we omit the details, such as how to define \bc{PERP} to appropriately mark the symbols. The simplest method is a linked list or table of some sort, that is filled by \bc{PERP} and consulted by the test word \bc{perps?}.

\TallC{How} might we implement a leading factor of $\gamma^{5}$? While there is no difficulty in taking traces of the form

Tr( 1'54 18 af ...) a iTr(e,..aA"B ’c‘y‘n ...), (11)

expressions with y5 between "starred" factors are more difficult.
However, the permutation properties of traces let us write, e.g.,

Tr((A +mA)(B+mB)y5¢(D+mD)E...)
(12)

ETI(YS¢(D+MD)E---(A +mi)(B+ms)).


token which stands for “ " " as shown on page 276. This token is;
marked orthogonal to all three of the vectors it represents, at the:
time it is inserted. '
To avoid further extending parse, probably the best scheme is to-i
define a distinct word, TigS(, that uses the components of parsed
to perform the above preliminary steps. Then 1195( will invokeli
parse to do the rest of its work. i

The only other significant task is to extend the output routine to ‘

a) recognize the special “ " ” token; and
b) replace dot products like “ " .d ” by [a,b,c,d].

A final remark: one or another form of vectoring can simplify
parse (relative to Fig. \ref{fig:11_05}) by hiding the recursion within words
that execute the branches. We have avoided this method here

because it conceals the algorithm, a distinct pedagogical disadvantage.

\section{FORmula TRANslator}

That prehistoric language FORTRAN -despite its manifold
deficiencies relative to FORTH - contains a useful and widely
imitated invention that helps maintain its popularity despite come
petition from more modern languages: This is the FORmula
TRANslator from which the name FORTRAN derives.

FORTH’s lack of FORmula TRANslator is keenly felt. Years of
scientific FORTH programming have not entirely eliminated my
habit of first writing a pseudo-FORI'RAN version of a new algo-
rithm before reexpressing it in FORTH. Sometimes I will even
write a test program in QuickBASIC‘D before re- coding it in
FORTH for speed and power, just to avoid worry about getting
the arithmetic expressions correct.

l
imam

awn-BMW 285

III mum

A FORmula TRANslator provides a nice illustration of rule-

d programming. To maintain portability, we employ the
standard FORTH kernel, omitting special HS/FORTH words as
well as CODE words.

In principle we could provide a true compiler that translates
formulae to machine code (or anng, to assembler). But unless
we use p-code or some such artifice we would lose all hope of
portability. Thus, we take instead the simpler course of translating
FORTRAN formulae to FORTH according to the rules

\begin{verbatim}
\ NUMBERS:
\ <int>        -> -| 0} {digit digit"8}
\ <exp't>      -> dDeEI{& | 0} {digit digit"2}| 0}
\ <fp#>        -> -|O} dig | Q} . dig" <exp't>

\ FORMULAS:
\ <assignment> -> <subject> = <expression>
\ <id>         -> letter {ietter|digit}"6
\ <subjec1>    -> <id>{<id|ist>10}
\ <idiist>     ->(<id> {,<id> ")
\ <arglist>    ->(<expr'n> {,<expr’n> }")
\ <function>   -> <id> <arglist>
\ <expression> -> <terrn> | < term> at <expr'n>
\ <term>       -> <factor> | <tactor> 96 <term>
\ <factor>     -> <id>| <tp#>| (<expr'n>) |
\end{verbatim}

-> <factor> “ <iactor>

Clearly, the FORTH FORmula TRANslator could become the
kernel of a more complete FORTRAN- >FORTH filter by ad-
ding to the above rules for formulae the following rules for loops
and conditionals:

\begin{verbatim}
\ DOLOOPS:

\ <label> -> <integer>
\ <lim> -> <integer>|<id>}
\ <step> -> ,<lim>|O}

\ <do> -> DO<label><id>=<iim>,<lim><step>

\ BRANCHING STRUCTURES:
\ < logical expr > - > <factor > .op. < factor >
\ <il0> -> IF(<Ioglcalexpr>)<assignment>
<if1 > -> IF(< logical expr>)THEN
{< statement > } "
END IF

<if2> -> lF(<Iogical expr>)THEN
{ < statement > } "
ELSE
{ < statement > } "
END IF


- > IF ( < logical expr > )THEN
{ < statement >} "
ELSEIF( < logical expr >)
{ < statement > } A
END IF

\end{verbatim}

§§2 Details of the Problem
The general principles of compiler writing are of course well
understood and have been described extensively elsewhere. ..
Several computer science texts expound programs for formula ‘
evaluators . Once we have our translator, we can easily make it
an evaluator by compiling the FORTH as a single word, then
invoking it.

 

Let us proceed by translating a FORTRAN formula into FORTH
code by hand. For simplicity, ignore integer arithmetic and as-
sume all literals will be placed on the intelligent foating point
stack (ifstack). Similarly assume all variable names in the pro- ,
gram refer to SCALARs (see Ch. 5). A word that has become
fairly standard is 96, which interprets a following number asE
foating point, and places it on the fstack. With these conventions,
we see that we shall want to translate an expression like

A - -15.3€7'EXP(7/X) + Z/(W-SINUHETA'Pl/lmyf
into (generic) FORTH something like this:

964 REAL’B >FS
96 1M REAL'B >FS
Pl G\

THEl’A >FS G‘
GSIN G

W >FS G -

Z >FS G\

X >FS

967 REAL'B G\
GEXP

96 45.357 REAL‘B >FS
Gt

G+

A FS>

Begin with the user interface. We will define a word, F' , that
will accept a terminated string and attempt to translate it to
FORTH. That is, we might say

F- A = -15,3E7*EXP(7/X) +Z/(W-SIN(THETA'PI/180)/4)'

and obtain the output (actual output from the working program!)

96 -15.3E7 REALM F>FS 96 7 REAL‘B F>FS
X>FS G/ GEXP G* Z>FS W>FS
THETA >FS Pl >FS G‘ 96 180 REAL‘B F>FS
G/ GSIN 96 4REAL‘8 F>FS G/ GNEGATE
G-l-G/ G+ AFS> 0k

Although the second version differs somewhat from the hand
translation, the two are functionally equivalent.

We would also like to have the possibility of compiling the emitted
FORTH words, if F' appears within a colon definition, as in

: do.B F' B = 39.37/ATAN(X“W) + 7"Z/X' ;

FORTRAN expression obeys the rules of algebra in a general-
y obvious fashion. Parentheses can be used to eliminate all
ambiguity and force a definite order on the evaluation of terms

esuuvuouoiaaa-Mmm.

Chapter 11 - Symbolic Programming Scientific FORTH

and factors. However, to reduce the number of parentheses,
FORTRAN adopted a heirarchy of operators that has been fol-
lowed by all other languages that incorporate semi-algebraic
replacement statements like the above. The heirarchy is

0. FUNCTION

1. EXPONEN'TIATION ( A or u)
2. t or/

3. + or -

4. “ , ” (argument separator in lists)

The translator must both enforce these rules and resolve am-
biguities involving operators at the same heirarchical level. Thus,
e.g., does the fragment

NB‘C

mean N(B*C) or (NB)*C ? Many FORTRAN compilers follow
the latter convention, so we will maintain this tradition.

Wd issue is the function library. The FORmula
slator must recognize functions, and be able to deter-
mine whether a given function is in the standard library. In the
example above, F" recognized EXP and SIN as standard library
functions and emitted the FORTH code to invoke them. Abeauty
of FORTH is that there are several easy ways to accomplish this,
using components of the FORTH kernel.

A third issue is the ability of a true FORTRAN compiler to
perform mixed-mode arithmetic, combining INTEGER'Z, IN-
TEGER‘4, INTEGER'8, REAL‘4, REAL'S, COMPLEX'S
and COMPLEX' 16 types ad libitem. FORTRAN does this using
the information contained in the type declarations at the begin-
ning of a routine. A pure FORmula TRANslator has no such
noncontextual information available to it, hence has no way to
decide how to insert the proper FORTH words during compila-
tion. To get around this we employ the generic data and operator
conventions developed in Chapter 5 §l.

swimmer" awn-OMW 2”

"3 Pm
Let us hand-parse the example, reproduced below:

A I -15.3€7'EXP(7/X) + Z/(W-SINCI'HETA'PII 1N)/4)

Clearly, we must apply the first rule

\ <assignment> -> <subiect> n <expression>

embodied in the word < assignment > . We split at the “ = " sign,
and interpret the text to its left as a SCALAH. Since we want to
emit the phrase A FS > last, yet have parsed it first, we have to
hold it somewhere. Clearly the buffer where we store it will be a
first-in last-out type; and by induction, last-in, first-out also. But
a LIFO buffer is a stack. Hence the fundamental data structure
needed in our parsing algorithm is a string stack. So we might
imagine that after the first parsing step the string stack contains

 

two strings
£SIACK Notes
A FS > \ < subject >

-15.3E7*EXP(7/X) + Z/(W-SlN('l’HETA"P|/180)/4) \ < expressio

Next we apply the rule
\ <expr'n> -> <term> |<term> a <axpr'n>

This breaks the top expression at the + sign between “ ) " and Z.
We should think of the two terms

-15.3E7*EXP(7/X)

and

as numbers on the ifstack; hence the code to evaluate each should
be emitted before the addition operator (that is, these expres-
sions are higher on the string stack than the addition operator
0 +). We adopt a rule that the right term is pushed before the
left, so the Sstack now looks like


A FS > \ < subject >
Z/(W-SIN(THETA*PI/180)/4) G + \ <term >
-15.3E7*EXP(7IX) \ < term >

We now anticipate a new problem: suppose we have somehow -
no need to worry about details yet - emitted the code for the
< term > -15.3E7*EXP(7/X) on top of the Sstack. Then we
would have to parse the line Z/(W-SINCI’ HETA'Pl/1 80)/4) G + .
Assuming the program knows how to handle the first part,
Z/(W-SIN(THETA"PI/180)/4), how will it deal with the G + ?
We do not want to use the space as a delimiter (an obvious out)
because this will cause trouble with A FS > .

The difficulty came from placing 6+ on the same line as
-1 5.3E7‘EXP(7/X). What if we had placed the operator on the
line above, as in

 

SSIACK Notes

A FS > \ < subject >
G + \ operator
Z/(W-SINUHETA'PI/180)/4) \ < term >
-15.3E7*EXP(7/X) \ < term >

Eventually we see this merely exchanges one problem for another
of equal difficulty: How do we distinguish a < factor > or
< term > that contains no more operators or functions - and is
therefore ready to be emitted as code - from the operator G +,
which contains a “ +” sign? Now we need complex expression
recognition, which will lead to a slow, complicated program.

When this sort of impasse arises (and I am pretending it had

been realized early in the design process, although the dif-
ficulty did not register until somewhat later) it signals that a key
issue has been overlooked. Here, we failed to distinguish FORTH
words, FS > and G +, from FORTRAN expressions. We have, in
effect, mixed disparate data types (like trying to add scalars and
vectors). Worse, we discarded too soon information that might

have been [BCfUI at a later stage. This leads to a programming tip,
a la Brodie :

I m: Never discard information. You might need it later.

Phrased this way. the solution becomes obvious: keep the
operators on a separate stack. whose level parallels the expres-
sions. So we now envision an expression stack and an operator
stack, which we call 13/8 and 0/5 for short. On two stacks,

E/S Q15 Notes
A FS > \ < subject >
Z/(W-SINCI‘HETA'Pi/180)/4) G + \ < term >
-15.3E7"EXP(7/X) NOP \ < term >

Why the NOPs (“no operation”) on the 0/8? We want to keep
the stack levels the same (so we do not have to check when
POPping off code strings); we thus have to put NOP on the 0/5
to balance a string on the BS.

The IDS now contains a < term > , so we apply the rules
\begin{verbatim}
\ <function> -> <id> <arglist>
\ <term> -> <iactor> | <factor> 96 <term>

\ <factor>-> <id>| <fp#>| (<expr’n>) |<func>
\end{verbatim}

We note there is an operator at the “ 96 " priority level (the “a"
in the TOS). We split the top < term > at this point, issuing a G'.

EIS QLSN.QIQ§
A FS > \ < subject >
Z/(W-SINO’HEI'A'Pl/180)/4) G + \ < term >
EXPO/X) G‘ \ (term >
-1 5.367 NOP


The parsing has now reached a turning point: the top string on
the E/S can be reduced no further. The program must recognize
this and emit the corresponding line of code (sec Ch. 5):

% -15.3E7 REALM F>FS

 

leaving

E18 018 Notes
A FS > \ < subject >
Z/(W-SIN (T HETA*P|/180)/4) G + \ < term >
NULL 6*
EXP(7/X) NOP \ < function >

What is NULL and why have we pushed it onto the E/S? Simply,
it is not yet time to emit the 6" so we have to save it; however,
we have another operator, G +, to associate with Z/(W-
SlN(THETA*PI/180)/4) . Thus we have no choice but to define a
placeholder for the 13/5, analogous to NOP on the 0/5.

S now contains a function. Assuming we can recognize it as
such, we want to check that it is in the library and put the
correct operator on the 13/5. Thus we want to decompose to

E15 018 Notes
A FS > \ < subject >
Z/(W-SIN(THETA*P|/180)/4) G + \ < term >
NULL 6*
NULL GEXP \ < function >
(7 IX) NOP \ < arglist >

The parentheses around the <arglist> on TOS serve no pur-
pose, so drop them.

We see, once again, an operator of the priority-level 96 (the “I”
between 7 and X), so we again apply the rule

\ <term> -> <factor> | <factor> 9i. <term>

to obtain

El: 013 Item

A F8 > \ < subject >
ZlM-SlNCFHETA'Pi/iwyf G + \ < term >
NULL G“

NULL GEXP

X G] \ < id >

7 NOP \ < ip\# >

Once again we can emit a number, so we do it:

96 7 REAL'B F> FS

Wait! Why did we say REALM with -15.3E7, but REAL'B with
7 just now? Can’t we make up our minds? The answer is that we
want to respect precision over-rides via FORTRAN's E (single
precision, so we say REALM) or D (double precision - REAL'B)
exponent prefixes. However, where we are free to choose, it
makes sense to keep maximum precision.

We continue, emitting the next simple items on the Sstack:

X G/ GEXP G‘

leaving

E18 018 Notes
A FS > \ < subject >
Z/(W-SlNCI’HETA'PI/180)l4) G + \ < term >

Once again we find the most exposed operator to be “ / which
we split with the rule

\ <term> -> <factor> | <factor> 96 <term>

E/S QLSN91§§

A FS> \ <subject>
NULL G + \ < term >
(ZW~SIN(THETA*Pi/180)/4) Slop \ ( < expr > )


Emit the T082
2 > PS
and apply the rule (first drop the parentheses)

\ <expr'n> -> <term> | <term> a <expr'n>

EIS Q15 Nona
A FS > \ < subject >
NULL G + \ < term >
NULL G/
-SIN(THEl'A*PI/180)/4 G +
W NOP

Why did we issue G + and keep the leading “-” sign with SIN?
Simple: any 9th grader can tell the difference between a “-”
binary operator (binop) and a “-” unary operator (unop) in an
expression. But, while not impossible, it is unnecessarily difficult
to program this distinction. The FORTH philosophy is “Keep it
simple!” Simplicity dictates that we embrace every opportunity
to avoid a decision, such as that between “-” binop and “-" unop.
The algebraic identity

X-YEX+(-Y)

lets us issue only G + , as long as we agree always to attac “-”
signs as unops to the expressions that follow them. Eventually,
of course, we shall have to deal with the distinction between
negative literals (-15.3E7, e.g.) and negation of variables. The
first we can leave alone, since the literal-handling word 96 (“treat
the following number as foating point and put it on the 87stack”)
surely knows how to handle a unary “-" sign; whereas the second
case will require us to issue a strategic GNEGATE.

A consequence of this method for handling “-” signs is that the
compiler will resolve the ambiguous expression

-X" =9 -(X") or (-X )Y

Mir-WW 295

in favor of the former alternative. if the latter is intended, it must
be specified with explicit parentheses.

After sending forth the phrase
W > PS

the leading “-" preceding SIN( ...)/4 must be dealt with. To
preserve the proper ordering on emission we will want a word
LEADING- that puts the token for GNEGATE on the 0/8 and
moves the string SiNCl'i-iETA'PI/i 00)“ to the TOS, issuing a
NOP on the BS, obtaining

E18 018 Ngtgs
A FS > \ < subject >
NULL G + \ < term >
NULL 6/
NULL G +
NULL GNEGATE
SIN (THETA'Pl/1 80)/4 NOP

The next exposed operator is at“ 96 " -level. We apply < term >
once more, to get:

EIS OLS Notes
NULL GNEGATE
4 G/
SINO‘HETA'PIHBO) NOP \ ( <expr'n> )

After handling the function as before we find the successive stacks
and FORTH code emissions

E/S MS Notes
A FS > \ < subject >
NULL G + \ < term >
NULL 6/
NULL G +
NULL, GNEGATE
4 GI
NULL GSIN

(THETA'PI/180) NOP


51 0/8 Joins
A FS > \ < subject >
NULL G + \ < term >
NULL 6/
NULL G +
NULL GNEGATE
4 GI
NULL GSIN
180 6/
PI 6*
THETA NOP

THETA >FS PI >FS G“ 96180 REAL*8 F>FS
G/ GSIN %4 REAL‘B F>FS G/ GNEGATE G+
G/ G+ AFS> ok

\subsection{Coding the FORmula TRANslator}

e proceed in the usual bottom-up manner. The first question

is how to define the Sstack. In the interest of brevity, I chose
not to push the actual strings on the E/S, but rather pointers to
their beginnings and ends. By using a token to represent the
operator, we can define a 6-byte wide stack which will point to
the text of interest (which itself resides in a buffer), and will hold
the token for the operator at the current level. This way only one
stack is pushed or popped and the levels never get out of
synchronization.

Again at the lowest level, we can develop the components that
recognize patterns, e.g., whether a piece of text is a foating point

number. The word that does the latter is \bc{fp\#?}, already described
in §2§§1.

A function is defined by the rule

\ <arglist> -> ( <expr'n> {, <expr'n>}")
\ <function> -> <id> <argl|st>

We may therefore identify a function by splitting at the first left
parenthesis,

sand scrum new
1- Beam 1mm ASCII ()- ,ii (
ooup - a> UNTIL'

and then applying appropriately defined FSMs to determine
whether the pieces are as they should be.

:<thction>($endSbeg--i)
DUP>R >( (--Send$beg')
UNDER 1- fi> <id>

-ROT SWAP <arglist> AND ;

The FSM < argllct > must be smart enough to exclude cases such
as

SIN(A + B)/(C-D)
and
SIN(A + B)/EXP(C-D)

that is, compound expressions that might contain functions; it
must also correctly recognize, e.g.,

SIN((A + B)/EXP(C-D))

as a function.

In FORTH there is no distinction between library functions and
functions we define ourselves. In either case, the protocol defined
in Chapter 8 will work fine. Thus the code generator for < func-
tion > emits the code

USE( fn.name arg1 argz argN F(x)

What, however, do we do about translating standard FORTRAN
names such as SIN, COS and EXP to their generic FORTH
equivalents? The simplest method defines words with the names
of the FORTRAN library functions. The FORTH-83 word fiND
locates the code-field address of a name residing in a string. Thus
we could have (note: .GSIN is a CONSTANT containing a token)

.GSIN CONSTANT sm \etc.

omvmtm-umm.

298 Chapter 11 - Symbolic Programming Scientific FORTH

:LIBRARY? ($end$beg--cta | 0)
-ROT UNDER - DUP>R
PADt+ SWAP CMOVE R> PAD CI \ makes
PAD fiND (--cia n) o= NOT AND ;

now we can define function! which, assuming pointers to the
< id > and < arglist > are on the stack, rearranges the Sstack like

this:
BS QIS Notes
(argt, argz, argN) .F(X) \ an op.
NULL .iib\_name \ if library function
or, if it is a user-defined function, like this:
E18 018 Notes
(arg1, argZ, argN) .F(X) \ an op.
name NOP \ user function

The code that does all this is

\begin{lstlisting}
: function! ($end2 $beg2 $end1 $beg1 - -)
.F(X) $push \ push arglist
DDUP LIBRARY? DUP 0=
IF DROP .NOP $push \ userfn
ELSE EXECUTE \ inlib.
NULL ROT $PUSH DDROP
THEN ." USE( " ;
\end{lstlisting}

For the program itself24 we work from the last word, < aslgn-

ment > , to the first (which we do not know the name of yet).
We shall describe the program in pseudocode only, in the interest
of saving space. Clearly,

\begin{lstlisting}
: < assignment > \ input $ assumed in buffer
<subj> = <expr> \ splitat "=" (- -t)
IF subjl THEN \ put Subj and its code on $staci<
.NOP $push ; \ then put expr on Sstack
\end{lstlisting}

Certain decisions need to be made here: for example, do we want
F' to be able to parse an expression that is not an assignment (that
is, generating code which evaluates the expression and leaves the
result on the ifstack)? We allowed this with the IF...THEN.

Next we pseudocode < oxproeeion >:
: <expression> empty? IF EXIT THEN
59°F


IF trm\&exprl RECURSE
ELSE NULL ROT $push
.NOP $push <term>
THEN ;

Defined recursively in this way, < oxpreoolon > will keep
working on the TOS until it has broken it up into term 5.

We similarly define < term > recursively, so it will break up any
term 5 into all their factors. It should also recognize < arglist > 5.
Thus:

: <term> empty? IF EXIT THEN

$pop < arglist >$
IF arglist! < expression > EXIT THEN
<factor>\%<term> (--f)\ splitat\%="/'

IF fct%trml RECURSE
ELSE .NOP $push$ <factor> \ term = factor
THEN ;

And finally, we define < factor > , again recursively,
\begin{lstlisting}
: <factor> empty? IF EXIT THEN \ done
SPOP <fp# > \ fp#?
IF fp#I RECURSE EXIT THEN
leading -?
IF leading-I < expression > \ forward ref.
EXIT THEN
< id > IF idI < expression > \ forward ref.
EXIT THEN
<f>"<f> \ exponent'?
IF f"fi RECURSE RECURSE
EXIT THEN
\ oont'd

< function >
IF functionl < expression > \ forward ref.
EXIT THEN

(< expression >) \ expression inside ( )?

IF exposel < expression > \ forward ref.
ELSE ." Notafactorl' ABORT THEN ;
\end{lstlisting}

\leftbar[1\linewidth]
Note the forward references found in \bc{<factor>}; since \bc{<expression >} is defined later, we must use vectored execution or some similar method to permit this recursive call.
\endleftbar

With this we conclude our discussion of rule-based programming. The complete code for the FORmula TRANslator is too lengthy to print, hence it will be found on the included diskette.